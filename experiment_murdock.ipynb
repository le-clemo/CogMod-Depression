{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import actr\n",
    "import pickle\n",
    "import random\n",
    "import os\n",
    "import fnmatch\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from itertools import groupby\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observed Issues:\n",
    "\n",
    "- Model acts weird when using 15 words\n",
    "  - Does it have to do with the way lists are created? Can't odd numbers (e.g.) be used for some reason?\n",
    "\n",
    "\n",
    "- Doesn't work with 40 words\n",
    "  - Again: check how lists are created.\n",
    "\n",
    "\n",
    "- Recency effect still too weak.\n",
    "  - Turn down utility of recall default PR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of words in each list i.e. list_length should be n where (n-2)%3 == 0 because 2 neutral words are added in each list.\n",
    "\n",
    "#### The adjustable parameters in this experiment code.\n",
    "    - Number of lists\n",
    "    - Number of words in each list\n",
    "    - The time taken for rehearsal (6 + delay of .5 seconds) and recall(10)\n",
    "#### Adjustable parameters in ACT-R\n",
    "    - :declarative-num-finsts 21 ; number of items that are kept as recently retrieved (Change it to 5) \n",
    "    - :declarative-finst-span 21 ; how long items stay in the recently-retrieved state (5,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Experiment part ###\n",
    "\n",
    "num_agents = 300 #set number of agents per condition\n",
    "\n",
    "def __init__(iteration, rehearsal_time, list_length, list_amount=3, path=\".\"):\n",
    "    subject = ''\n",
    "\n",
    "    current_list = ''\n",
    "\n",
    "    recalled_words = defaultdict(list)\n",
    "\n",
    "    rehearsed_words =  defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    #list_amount = 3   # No of lists (100, 200, 1000, 2000 AND 5000)\n",
    "\n",
    "    #Set below where function is actually called\n",
    "    list_length = list_length   # No of words in a list\n",
    "    rehearsal_time = rehearsal_time  # No of seconds for which rehearsal happens and each word is shown\n",
    "\n",
    "    delay = 1  #delay between rehearsal and recall\n",
    "\n",
    "    recall_time = 90\n",
    "\n",
    "    word_lists_dict = defaultdict(list)\n",
    "    \n",
    "    # Ensure there are enough unique words to create the word lists\n",
    "    word_dict = {\"positive\": [\"positive\" + str(i) for i in range(999)],\n",
    "                 \"negative\": [\"negative\" + str(i) for i in range(999)],\n",
    "                 \"neutral\": [\"neutral\" + str(i) for i in range(999)]}\n",
    "\n",
    "    filename = f'{path}\\words_{list_length}_lists_{list_amount}_rh_time_{rehearsal_time}_rec_time_{recall_time}_delay_{delay}_{iteration}.txt'\n",
    "    \n",
    "    results = {}\n",
    "\n",
    "    results['x'] = {'data': [], # will be appended later in the analytics function\n",
    "                          'info': \"Storing range(len(word_lists_dict[0])) here\"}\n",
    "\n",
    "    results['rehearse_frequency'] = {'data': None,# will be appended later in the analytics function\n",
    "\n",
    "                                     'info': \"Storing list(rehearse_frequency.values()) here\"}\n",
    "\n",
    "    results['recall_probability'] = {'data': None, # will be appended later in the analytics function\n",
    "                                        'info': \"Storing list(recall_probability.values()) here\"}\n",
    "\n",
    "    results['first_recall'] = {'data': None, # will be appended later in the analytics function\n",
    "                               'info': \"Storing list(first_probability.values()) here\"}\n",
    "\n",
    "    with open(filename, 'w') as outfile:\n",
    "        json.dump(results, outfile)\n",
    "\n",
    "    with open(filename) as json_file:\n",
    "        results = json.load(json_file)\n",
    "#         #print(results)\n",
    "    \n",
    "    globals().update(locals())  ## Making everything public, worst code you can ever write!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_words(i, list_length):\n",
    "    '''\n",
    "    Add the words to the word lists, ensures valence categories are balanced\n",
    "    '''\n",
    "    global word_lists_dict\n",
    "\n",
    "    amnt_wanted = list_length #-2)/3 #not needed here because Murdock experiment # Amount of each valence wanted, minus 2 neutrals controlling for primacy\n",
    "    amt_positive, amt_negative, amt_neutral, count = 0, 0, 0, 0\n",
    "    while len(word_lists_dict[i]) != list_length:\n",
    "        count += 1\n",
    "        #print(f\"...................{count,word_lists_dict[i]}\")\n",
    "        if count >= 9999: # IF it takes too long to create a unique list at random, start over\n",
    "            word_lists_dict[i] = []\n",
    "            add_words(i, list_length)\n",
    "        if len(word_lists_dict[i]) == 0: # Place two neutral words at the start to control for primacy effects\n",
    "            word_to_add1 = word_dict[\"neutral\"][random.randint(0, len(word_dict[\"neutral\"])-1)]\n",
    "            word_to_add2 = word_dict[\"neutral\"][random.randint(0, len(word_dict[\"neutral\"])-1)]\n",
    "            if word_to_add1 not in word_lists_dict[i] and word_to_add2 not in word_lists_dict[i] and word_to_add1 != word_to_add2:\n",
    "                word_lists_dict[i].append(word_to_add1)\n",
    "                word_lists_dict[i].append(word_to_add2)\n",
    "            else:\n",
    "                continue # skip this loop iteration                   \n",
    "        else: \n",
    "            random_valence = random.choice([\"positive\", \"negative\", \"neutral\"])\n",
    "            word_to_add = word_dict[random_valence][random.randint(0, len(word_dict[random_valence])-1)]\n",
    "            if word_to_add not in word_lists_dict[i] and word_lists_dict[i][-1] not in word_dict[random_valence] and \\\n",
    "               amt_positive <= amnt_wanted and amt_negative <= amnt_wanted and amt_neutral <= amnt_wanted:\n",
    "                if random_valence == \"positive\" and amt_positive < amnt_wanted:\n",
    "                    amt_positive += 1\n",
    "                elif random_valence == \"negative\" and amt_negative < amnt_wanted:\n",
    "                    amt_negative +=1\n",
    "                elif random_valence == \"neutral\" and amt_neutral < amnt_wanted:\n",
    "                    amt_neutral +=1\n",
    "                else:\n",
    "                    continue # skip this loop iteration\n",
    "                word_lists_dict[i].append(word_to_add)\n",
    "\n",
    "def create_lists(list_amount=3, list_length=2):\n",
    "    '''\n",
    "    Create the wordlists used during the free recall tasks \n",
    "    '''  \n",
    "    global word_lists_dict \n",
    "\n",
    "    for i in range(list_amount):\n",
    "        print(f'List {i+1}/{list_amount} created!', end=\"\\r\")\n",
    "        add_words(i, list_length)\n",
    "\n",
    "    # Save the dictionary to a .pickle file, so we do not have to create the word lists everytime we run the model                    \n",
    "    file = open(f\"word_lists/word_lists_dict_{list_length}_{list_amount}.pickle\",\"wb\")\n",
    "    pickle.dump(word_lists_dict, file)\n",
    "    file.close()\n",
    "    return word_lists_dict\n",
    "\n",
    "# Check if the word lists already exist, else create new word lists\n",
    "def check_and_create_lists():\n",
    "    global word_lists_dict\n",
    "    try:\n",
    "        file = open(f\"word_lists/word_lists_dict_{list_length}_{list_amount}.pickle\",\"rb\")\n",
    "        #file = open(f\"word_lists_dict_100_items_only.pickle\",\"rb\")\n",
    "        word_lists_dict = pickle.load(file)  \n",
    "        file.close()\n",
    "        print(\"\\nSuccesfully loaded the word lists!\\n\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"\\nCreating word lists!\\n\")\n",
    "        #amount_to_create = list_amount                              \n",
    "        word_lists_dict = create_lists(list_amount,list_length)\n",
    "\n",
    "def display_word_lists():\n",
    "    '''\n",
    "    Display the word lists loaded/created\n",
    "    '''\n",
    "    for key, value in word_lists_dict.items():\n",
    "        print(f'List {key}:\\n {value}\\n')\n",
    "\n",
    "def close_exp_window():\n",
    "    '''\n",
    "    Close opened ACT-R window\n",
    "    '''\n",
    "    return actr.current_connection.evaluate_single(\"close-exp-window\")\n",
    "\n",
    "def prepare_for_recall(): \n",
    "    '''\n",
    "    Disable rehearsing productions, and clearing buffer contents to start the recalling phase \n",
    "    '''\n",
    "    disable_list = [\"rehearse-first\", \"rehearse-second\", \"rehearse-third\", \"rehearse-fourth\", \n",
    "                    \"retrieve-it\", \"rehearse-first-default\", \"rehearse-second-default\",\n",
    "                    \"rehearse-third-default\", \"rehearse-fourth-default\", \"rehearse-it\"\n",
    "                   \"skip-first, skip-second\", \"skip-third\", \"skip-fourth\"]\n",
    "    \n",
    "    for prod in disable_list:\n",
    "        actr.pdisable(prod)\n",
    "    actr.run(delay, False) \n",
    "    for buff in [\"imaginal\", \"retrieval\", \"production\"]:\n",
    "        actr.clear_buffer(buff)  \n",
    "\n",
    "def setup_dm(word_list):\n",
    "    '''\n",
    "    Add words to declarative memory, since it can be assumed the test subjects know the English language already\n",
    "    '''\n",
    "    #print(\"\\n\\n############################################# Inside setup_dm i.e. Declarative Memory\")\n",
    "     \n",
    "    colour_conversion = {'pos': 'GREEN', 'neg': 'RED', 'neu': 'BLACK'}\n",
    "    for idx, word in enumerate(word_list):\n",
    "        valence = ''.join([char for char in word if not char.isdigit()])[:3]\n",
    "        actr.add_dm(('item'+str(idx), 'isa', 'memory', 'word', \"'\"+word+\"'\"))#, 'valence', colour_conversion[valence]))\n",
    "#         if idx == 0:\n",
    "#             print(\"\\n Emaple of a chunk added in Declarative Memory is \\n\")\n",
    "#             print('item'+str(idx), 'isa', 'memory', 'word', \"'\"+word+\"'\", 'valence', colour_conversion[valence],\"\\n\")\n",
    "        \n",
    "\n",
    "def setup_experiment(human=True):\n",
    "    '''\n",
    "    Load the correct ACT-R model, and create a window to display the words\n",
    "    '''\n",
    "#     print(\"\\n\\n############################################# Inside setup_experiment\")\n",
    "#     print(f'\\nSubject = {subject}\\n')  \n",
    "\n",
    "    loaded = None\n",
    "    if subject == \"controls\":\n",
    "        loaded = actr.load_act_r_model(r\"C:\\Users\\cleme\\Documents\\Education\\RUG\\First-Year_Research\\My_Project\\Model\\models\\general_free_recall_model_v2.lisp\")\n",
    "        #loaded = actr.load_act_r_model(r\"C:\\Users\\cleme\\Documents\\Education\\RUG\\First-Year_Research\\My_Project\\Model\\models\\csm_free_recall_model.lisp\")\n",
    "    elif subject == \"depressed\":\n",
    "        loaded = actr.load_act_r_model(r\"\")\n",
    "\n",
    "    #print(\"\\n\\n############################################# Inside setup_experiment\")\n",
    "    #print(f'\\nLoaded Act-r model = {loaded}\\n')  \n",
    "\n",
    "\n",
    "\n",
    "    window = actr.open_exp_window(\"Free Recall Experiment\", width=1024, height=768, visible=human) # 15inch resolution window\n",
    "    actr.install_device(window) \n",
    "    return window    \n",
    "\n",
    "def record_words_recalled(item):\n",
    "    '''\n",
    "    Register which words were recalled during the experiment for a specific wordlist and strip the numbers\n",
    "    '''\n",
    "    valence = ''.join(char for char in item if not char.isdigit())\n",
    "    item_idx = ''.join(char for char in item if char.isdigit())\n",
    "    recalled_words[current_list].append((valence, item_idx))\n",
    "\n",
    "def record_words_rehearsed(item):\n",
    "    '''\n",
    "    Register amount of rehearsals per word for each wordlist\n",
    "    '''\n",
    "    rehearsed_words[current_list][item] += 1\n",
    "\n",
    "def create_lplot(idx, xlabel, ylabel, x, y, xticks_len, filename, ytick_range=None, show=False):\n",
    "    '''\n",
    "    Create line plot using matplotlib\n",
    "    '''\n",
    "    plt.figure(idx)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.plot(x, y)\n",
    "    plt.xticks(np.arange(0, xticks_len, 1)) \n",
    "    plt.yticks(ytick_range)\n",
    "    #plt.savefig(\"images/\"+subject+\"_\"+filename, bbox_inches='tight')\n",
    "    if show:\n",
    "        plt.show()    \n",
    "\n",
    "        \n",
    "def create_result_dict():\n",
    "    '''\n",
    "    Use a module-level function, instead of lambda function, to enable pickling it\n",
    "    '''\n",
    "    return defaultdict(int)\n",
    "\n",
    "## Creating different pickle files to store results from multiple hyper-parameter values.\n",
    "\n",
    "\n",
    "def analysis(wlist_amount, show_plots=False):\n",
    "    '''\n",
    "    Review results of the recall experiment\n",
    "    '''\n",
    "    global results\n",
    "    result_dict = defaultdict(create_result_dict) # instead of defaultdict(lambda: defaultdict(int))\n",
    "    first_recall = defaultdict(int)\n",
    "    recall_probability = defaultdict(int)\n",
    "    rehearse_frequency = defaultdict(int)\n",
    "    transitions_amnt = 0\n",
    "    thought_train_len = []\n",
    "\n",
    "    for key, val in recalled_words.items():\n",
    "        thought_train_len.extend([(k, sum(1 for _ in count)) for k, count in groupby([val[0] for val in val[2:]])])\n",
    "        for idx, (retrieved_word, item_num) in enumerate(val[2:]):\n",
    "            if idx != 0:\n",
    "                if retrieved_word != val[2:][idx-1][0]:\n",
    "                    transitions_amnt += 1/wlist_amount # average over word lists\n",
    "\n",
    "    print(f'Avg. Amount of recall transitions = {int(transitions_amnt)}')\n",
    "    neg_thought_train_len = 0\n",
    "    neg_divider = 0.0001\n",
    "    for x in thought_train_len:\n",
    "        if x[0] == 'negative':\n",
    "            neg_divider += 1\n",
    "            neg_thought_train_len += x[1]\n",
    "    print(f'Avg. Negative Thought train length = {round(neg_thought_train_len/neg_divider, 3)}')            \n",
    "\n",
    "    for list_num, wlist in word_lists_dict.items():\n",
    "        if list_num < wlist_amount:\n",
    "            for key, val in recalled_words.items():\n",
    "                if key==list_num:\n",
    "                    first_recall[wlist.index(''.join(val[0]))] += 1   \n",
    "                    for idx, word in enumerate(wlist):\n",
    "                        first_recall[idx] += 0\n",
    "                        if ((''.join(char for char in word if not char.isdigit()), \n",
    "                             ''.join(char for char in word if char.isdigit()))) in val:\n",
    "                            recall_probability[idx] += 1\n",
    "                        else:\n",
    "                            recall_probability[idx] += 0                            \n",
    "                for retrieved_word, item_num in val[2:4]:\n",
    "                    result_dict[\"pstart\"][retrieved_word] += 1  \n",
    "                for retrieved_word, item_num in val[4:-2]:\n",
    "                    result_dict[\"pstay\"][retrieved_word] += 1\n",
    "                for retrieved_word, item_num in val[-2:]:\n",
    "                    result_dict[\"pstop\"][retrieved_word] += 1                                                        \n",
    "            for key, val in rehearsed_words.items():\n",
    "                if key==list_num:\n",
    "                    for idx, word in enumerate(wlist):\n",
    "                        rehearse_frequency[idx] += rehearsed_words[key][word]\n",
    "    \n",
    "    for key, val in first_recall.items():\n",
    "        first_recall[key] = val/wlist_amount\n",
    "\n",
    "    for key, val in recall_probability.items():\n",
    "        recall_probability[key] = val/wlist_amount\n",
    "\n",
    "    for key, val in rehearse_frequency.items():\n",
    "        rehearse_frequency[key] = val/wlist_amount      \n",
    "        \n",
    "    \n",
    "\n",
    "    xticks_len = len(word_lists_dict[0])\n",
    "    \n",
    "    \n",
    "    #results['x']['data'].append(range(len(word_lists_dict[0])))\n",
    "    #results['xticks_len']['data'].append(len(word_lists_dict[0]) )\n",
    "    results['rehearse_frequency']['data'] = list(rehearse_frequency.values())\n",
    "    results['recall_probability']['data'] = list(recall_probability.values())\n",
    "    results['first_recall']['data'] = list(first_recall.values()) \n",
    "    \n",
    "    with open(filename, 'w') as outfile:\n",
    "        json.dump(results, outfile)\n",
    "        \n",
    "    create_lplot(0, 'Serial input position', 'Rehearse Frequency', range(len(word_lists_dict[0])), list(rehearse_frequency.values()), \n",
    "                xticks_len, f'rehearse_frequency_{list_length}_{list_amount}_{rehearsal_time}_{recall_time}_{delay}.png', None, show_plots)\n",
    "\n",
    "    create_lplot(1, 'Serial input position', 'Starting Recall', range(len(word_lists_dict[0])), list(first_recall.values()), \n",
    "                xticks_len, f'starting_recall_{list_length}_{list_amount}_{rehearsal_time}_{recall_time}_{delay}.png', np.arange(0, .5, .1), show_plots)                \n",
    "\n",
    "    create_lplot(2, 'Serial input position', 'Recall Probability', range(len(word_lists_dict[0])), list(recall_probability.values()), \n",
    "                xticks_len, f'recall_probability_{list_length}_{list_amount}_{rehearsal_time}_{recall_time}_{delay}.png', np.arange(0, 1, .1), show_plots)   \n",
    "    \n",
    "#     create_lplot(3, 'Serial input position', 'Accuracy', range(len(word_lists_dict[0])), list(recall_accuracy.values()), \n",
    "#                 xticks_len, 'recall_accuracy.png', np.arange(0, 1, .1), show_plots) \n",
    "\n",
    "    file = open(\"results_\"+subject+\".pickle\",\"wb\")\n",
    "    pickle.dump(result_dict, file)\n",
    "    file.close()\n",
    "\n",
    "    return result_dict\n",
    "\n",
    "def do_experiment(subj=\"depressed\", human=False, wlist_amount=2000):\n",
    "    '''\n",
    "    Run the experiment\n",
    "    '''\n",
    "    check_and_create_lists()\n",
    "    global subject,word_lists_dict\n",
    "    subject = subj\n",
    "    assert wlist_amount <= len(word_lists_dict), \"Chosen too many lists, choose less or create more word lists using function: create_lists()\"\n",
    "    \n",
    "#     print(\"###################################################\\n\")\n",
    "#     print(\"The original word list \\n\")\n",
    "#     print(display_word_lists())\n",
    "    \n",
    "#     print(\"\\n###################################################\\n\")\n",
    "#     print(\"Experiment started, Trying to understand the flow\\n\")\n",
    "  \n",
    "    for idx, (key, value) in enumerate(word_lists_dict.items()):\n",
    "        actr.reset()\n",
    "        window = setup_experiment(human)\n",
    "        \n",
    "        #actr.get_parameter_value(\":dat\")\n",
    "        #actr.set_buffer_chunk(\"wm\", \"init\", requested=True)\n",
    "        \n",
    "        global current_list\n",
    "        current_list = idx # keep track for which list words are recalled\n",
    "        setup_dm(value)   \n",
    "        actr.add_command(\"retrieved-word\", record_words_recalled,\"Retrieves recalled words.\")\n",
    "        actr.add_command(\"rehearsed-word\", record_words_rehearsed,\"Retrieves rehearsed words.\")\n",
    "#         print(\"\\n##################  Model started rehearsal \")\n",
    "        for idx, word in enumerate(value):\n",
    "            if \"neutral\" in word:\n",
    "                color = \"black\"\n",
    "            elif \"positive\" in word:\n",
    "                color = \"green\"\n",
    "            else:\n",
    "                color = \"red\"\n",
    "            actr.add_text_to_exp_window(window, word, x=475-len(word) , y=374, color=color, font_size=20) # change later \n",
    "            print(idx, word)\n",
    "            actr.run(rehearsal_time, human) # True when choosing Human, False when choosing differently\n",
    "            actr.clear_exp_window(window)\n",
    "            actr.run(0.5, human)  # 500-ms blank screen \n",
    "            \n",
    "        print(rehearsal_time)\n",
    "        \n",
    "        prepare_for_recall()       \n",
    "        actr.remove_command(\"rehearsed-word\")\n",
    "#         print(\"\\n##################  Model finished rehearsal, list of rehearsed words is \")\n",
    "#         print(f'{rehearsed_words}\\n')\n",
    "#         print(\"\\n##################  Model started recall \")\n",
    "        actr.goal_focus(\"startrecall\") # set goal to start recalling\n",
    "        actr.run(recall_time, human)  \n",
    "        actr.remove_command(\"retrieved-word\")\n",
    "#         print(\"\\n##################  Model finished recall, list of recalled words is \")\n",
    "#         print(f'{recalled_words}\\n')\n",
    "        print(f'Experiment {idx+1}/{wlist_amount} completed!', end=\"\\r\")\n",
    "        if idx == wlist_amount-1: # run for a chosen amount of word lists\n",
    "            break\n",
    "    close_exp_window() # close window at end of experiment     \n",
    "\n",
    "    avg_recalled, avg_recalled_unique = 0, 0\n",
    "    for key, val in recalled_words.items():\n",
    "        avg_recalled += len(val)\n",
    "        avg_recalled_unique += len(set(val))\n",
    "    #    print(f'\\nList {key} (length={len(val)}, unique={len(set(val))})')\n",
    "    \n",
    "    num_recalled = avg_recalled//wlist_amount\n",
    "    num_unique_recalled = avg_recalled_unique//wlist_amount\n",
    "    \n",
    "    print(f'Avg. Number of words recalled = {num_recalled}')\n",
    "    print(f'Avg. Number of unique words recalled = {num_unique_recalled}')\n",
    "    \n",
    "    results = analysis(list_amount, False)        \n",
    "\n",
    "    for key, val in results.items():\n",
    "        print(f'{key} = {dict(val)}')\n",
    "    print()\n",
    " \n",
    "\n",
    "    print(\"\\n\\n#############################################\")\n",
    "    print(f'\\n[{subj}] Results!\\n')\n",
    "    return num_recalled, num_unique_recalled, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_lists = 1 #number of lists per agent\n",
    "\n",
    "#to save files to different directory for different numbers of agents\n",
    "output_path = f'./murdock/agents_{num_agents}/'\n",
    "if not os.path.isdir(output_path):\n",
    "    os.mkdir(f'murdock/agents_{num_agents}/')\n",
    "path = output_path\n",
    "\n",
    "#experimental conditions [rehearsal time, list length] from Murdock 1962 \n",
    "experimental_setup = [[2,15], [2,20], [1,20], [1,40]] #\n",
    "\n",
    "total_recalled = 0\n",
    "total_unique = 0\n",
    "\n",
    "for parameter in experimental_setup:\n",
    "    rh = parameter[0]\n",
    "    ll = parameter[1]\n",
    "    \n",
    "    print(\"---------------------------------\")\n",
    "    print(\"Experimental condition:\")\n",
    "    print(f\"Number of lists: {num_lists}\")\n",
    "    print(f\"Words per list: {ll}\")\n",
    "    print(f\"Rehearsal time: {rh} seconds\")\n",
    "    \n",
    "    for agent in range(num_agents):\n",
    "        print(\"------------------------------\")\n",
    "        print(f\"Started for agent_{agent}\")\n",
    "        print(f\"Words per list: {ll}, rehearsal time: {rh} sec\")\n",
    "        __init__(agent, rehearsal_time=rh, list_length=ll, list_amount=num_lists, path=path)\n",
    "\n",
    "        try:\n",
    "            num_recalled, num_unique, results = do_experiment('controls',False,list_amount)\n",
    "            total_recalled += num_recalled\n",
    "            total_unique += num_unique\n",
    "        except ValueError:\n",
    "            print(\"\\nAgent recalled 0 items.\")\n",
    "\n",
    "    avg_recall = total_recalled // num_agents\n",
    "    avg_unique = total_unique / num_agents\n",
    "    print(f\"Experimental Condition\\nWords per list: {ll}, rehearsal time: {rh} sec\")\n",
    "    print(f\"\\nAverage number of recalled words ({num_agents} agents): {avg_recall}\")\n",
    "    print(f\"Unique: {avg_unique}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_list_length = 40\n",
    "f, ax = plt.subplots(1) #set up plot\n",
    "\n",
    "for parameter in experimental_setup:\n",
    "    rh = parameter[0] #rehearsal time\n",
    "    ll = parameter[1] #words per list\n",
    "\n",
    "    files = [] #Storing all the relevant files to work on them later\n",
    "    pattern = f\"words_{ll}_lists_{num_lists}_rh_time_{rh}*.txt\" # Pattern for matching the filename for data retreival\n",
    "    for file in os.listdir(path): #Lists all the files and directories within the folder\n",
    "        #print(file)\n",
    "        if fnmatch.fnmatch(file, pattern): #matches the above declared patter with the filenames from listdir()\n",
    "            #print(file)\n",
    "            files.append(file) #Appends to files to make it available for later use.\n",
    "    \n",
    "    # Initializing all the parameters needed for the plots\n",
    "    idx = [0,1,2]\n",
    "    xlabel = 'Serial Input Position'\n",
    "    ylabel = ['Rehearse Frequency','Starting Probability','Recall Probability']\n",
    "    xticks_len = max_list_length\n",
    "    rehearse_frequency = []\n",
    "    recall_probability = []\n",
    "    first_recall = []\n",
    "    \n",
    "    for file in files: #load the result files\n",
    "        with open(f\"{path}/{file}\") as f:\n",
    "            results = json.load(f)\n",
    "            if results['recall_probability']['data']:\n",
    "                recall_probability.append(results['recall_probability']['data'])\n",
    "            else: #if an agent failed to recall anything...\n",
    "                recall_probability.append([0]*ll)\n",
    "                \n",
    "    #calculating avg recall probability per input position across agents            \n",
    "    avg_recall_probs = [sum(x)/num_agents for x in zip(*recall_probability)]\n",
    "     \n",
    "    #plot results\n",
    "    x = range(ll)\n",
    "    ax.plot(x, avg_recall_probs, label = f\"{ll} items, {rh} sec\")    \n",
    "    \n",
    "ax.legend()\n",
    "\n",
    "#(\"murdock/images/\"+subject+\"_\"+filename, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### do_experiment flow:\n",
    "\n",
    "1. check_and_create_lists\n",
    "\ta. create_lists\n",
    "\t   return word_lists_dict\n",
    "\t\ti. add_words\n",
    "            adds to word_lists_dict\n",
    "\n",
    "2. setup_experiment\n",
    "    return window\n",
    "\n",
    "\n",
    "3. setup_dm\n",
    "\n",
    "\n",
    "4. prepare_for_recall\n",
    "\n",
    "\n",
    "5. close_exp_window\n",
    "\n",
    "\n",
    "6. analysis\n",
    "    return result_dict\n",
    "        contains pstart, pstay, pstop\n",
    "    prints Avg recall transitions\n",
    "    \n",
    "    prints Avg negative thought train length\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = []\n",
    "with (open(\"word_lists/word_lists_dict_40_31.pickle\", \"rb\")) as openfile:\n",
    "    while True:\n",
    "        try:\n",
    "            objects.append(pickle.load(openfile))\n",
    "        except EOFError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recalled_words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
