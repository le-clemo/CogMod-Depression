{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(5000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 5 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACT-R connection has been started.\n"
     ]
    }
   ],
   "source": [
    "import actr\n",
    "import pickle\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict,Counter\n",
    "from itertools import groupby,combinations\n",
    "import json\n",
    "from IPython.display import Image \n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Existing Problems\n",
    "    \n",
    "    1. BIG PROBLEM: The items recalled in the first list are somehow coming from the second list as well.\n",
    "    Ex: Original Lists \n",
    "    {0: {0: 'neutral537', 1: 'neutral871', 2: 'negative262', 3: 'neutral154', 4: 'positive552'}, \n",
    "    1: {0: 'neutral281', 1: 'neutral889', 2: 'negative842', 3: 'positive771', 4: 'neutral457'}, \n",
    "    2: {0: 'neutral388', 1: 'neutral429', 2: 'positive213', 3: 'negative659', 4: 'neutral848'}, \n",
    "    3: {0: 'neutral13', 1: 'neutral553', 2: 'positive179', 3: 'negative293', 4: 'neutral935'}})\n",
    "    ------------------------------\n",
    "    ------------------------------\n",
    "    Recalled Lists \n",
    "    {0: ['neutral388', 'positive213', 'neutral457', 'negative842', 'negative659', 'neutral889', 'neutral848'], \n",
    "    1: ['neutral388', 'positive213', 'neutral457', 'negative842', 'negative659', 'neutral889', 'neutral848'], \n",
    "    2: ['neutral388', 'positive213', 'neutral457', 'negative842', 'negative659', 'neutral889', 'neutral848'], \n",
    "    3: ['neutral388', 'positive213', 'neutral457', 'negative842', 'negative659', 'neutral889', 'neutral848']})\n",
    "    \n",
    "    \n",
    "    2. There is no recall many times even with 0 delay which should never be the case.\n",
    "    3. The lists always contains 2 more neutral words (for primacy) was it the same in original experiments?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postman lag-CRP\n",
    "\n",
    "    - Hyperparameters: list_amount, list_length, delay, recall_time, no_of_agents\n",
    "    - list_amount and no_of_agents : 30 to keep it statistically significant\n",
    "    - list_length and delay are varied \n",
    "    - recall time is 60 seconds as in Postman's original experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Experiment part ###\n",
    "def __init__(iteration):\n",
    "    subject = ''\n",
    "\n",
    "    current_list = ''\n",
    "\n",
    "    list_amount = 1   # No of lists (100,200, 1000, 2000 AND 5000)\n",
    "\n",
    "    list_length = 30   # No of words in a list\n",
    "\n",
    "    rehearsal_time = 1  # No of seconds for which rehearsal happens and each word is shown\n",
    "\n",
    "    delay = 0  #delay between rehearsal and recall\n",
    "\n",
    "    recall_time = 60\n",
    "    \n",
    "    list_keys = list(range(list_amount))\n",
    "    value = []\n",
    "    recalled_words = dict.fromkeys(list_keys,value)\n",
    "    \n",
    "    rehearsed_words =  defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    word_lists_dict = defaultdict(list)\n",
    "    word_indices_dict = defaultdict(dict)\n",
    "   \n",
    "    # Ensure there are enough unique words to create the word lists\n",
    "    word_dict = {\"positive\": [\"positive\" + str(i) for i in range(999)],\n",
    "                 \"negative\": [\"negative\" + str(i) for i in range(999)],\n",
    "                 \"neutral\": [\"neutral\" + str(i) for i in range(999)]}\n",
    "   \n",
    "      # Ensure there are enough unique words to create the word lists\n",
    "#     word_dict = {\"positive\": [\"positive\" + str(i) for i in range(list_length)],\n",
    "#                  \"negative\": [\"negative\" + str(i) for i in range(list_length)],\n",
    "#                  \"neutral\": [\"neutral\" + str(i) for i in range(list_length)]}\n",
    "\n",
    "    all_unique_words = set()\n",
    "    \n",
    "    extra_list_intrusions = 0\n",
    "    \n",
    "    if not os.path.exists(f'lag_crp_plots_postman/delay_{delay}'):\n",
    "        os.mkdir(f'lag_crp_plots_postman/delay_{delay}')\n",
    "        \n",
    "#     if not os.path.exists(f'./lag_crp_plots/delay_{delay}/words_{list_length}'):\n",
    "#         os.mkdir(f'./lag_crp_plots/delay_{delay}/words_{list_length}')\n",
    "        \n",
    "    filename = f'lag_crp_plots_postman/delay_{delay}/words_{list_length}.txt'\n",
    "    \n",
    "    results = {}\n",
    "\n",
    "\n",
    "\n",
    "    # results['x'] = {'data': [], # will be appended later in the analytics function\n",
    "    #                      'info': \"Storing range(len(word_lists_dict[0])) here\"}\n",
    "\n",
    "    results['rehearse_frequency'] = {'data': None,# will be appended later in the analytics function\n",
    "\n",
    "                                     'info': \"Storing list(rehearse_frequency.values()) here\"}\n",
    "\n",
    "    results['recall_probability'] = {'data': None, # will be appended later in the analytics function\n",
    "                                     'info': \"Storing list(recall_probability.values()) here\"}\n",
    "\n",
    "    results['first_recall'] = {'data': None, # will be appended later in the analytics function\n",
    "                               'info': \"Storing list(first_probability.values()) here\"}\n",
    "    \n",
    "    results['lag_crps'] = {'data': None, # will be appended later in the analytics function\n",
    "                               'info': \"Storing lag_crps for each agent here\"}\n",
    "\n",
    "    with open(filename, 'w') as outfile:\n",
    "        json.dump(results, outfile)\n",
    "\n",
    "    with open(filename) as json_file:\n",
    "        results = json.load(json_file)\n",
    "        #print(results)\n",
    "    \n",
    "    globals().update(locals())  ## Making everything public, worst code you can ever write!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_words(i, list_length):\n",
    "    '''\n",
    "    Add the words to the word lists, ensures valence categories are balanced\n",
    "    '''\n",
    "    global word_lists_dict,word_indices_dict\n",
    "\n",
    "    amnt_wanted = (list_length -2)/3   # Amount of each valence wanted, minus 2 neutrals controlling for primacy\n",
    "    amt_positive, amt_negative, amt_neutral, count = 0, 0, 0, 0\n",
    "    while len(word_lists_dict[i]) != list_length:\n",
    "        count += 1\n",
    "        #print(f\"...................{count,word_lists_dict[i]}\")\n",
    "        if count >= 9999: # IF it takes too long to create a unique list at random, start over\n",
    "            word_lists_dict[i] = []\n",
    "            add_words(i, list_length)\n",
    "        if len(word_lists_dict[i]) == 0: # Place two neutral words at the start to control for primacy effects\n",
    "            word_to_add1 = word_dict[\"neutral\"][random.randint(0, len(word_dict[\"neutral\"])-1)]\n",
    "            word_to_add2 = word_dict[\"neutral\"][random.randint(0, len(word_dict[\"neutral\"])-1)]\n",
    "            if word_to_add1 not in word_lists_dict[i] and word_to_add2 not in word_lists_dict[i] and word_to_add1 != word_to_add2:\n",
    "                word_lists_dict[i].append(word_to_add1)\n",
    "                word_lists_dict[i].append(word_to_add2)\n",
    "            else:\n",
    "                continue # skip this loop iteration                   \n",
    "        else: \n",
    "            random_valence = random.choice([\"positive\", \"negative\", \"neutral\"])\n",
    "            word_to_add = word_dict[random_valence][random.randint(0, len(word_dict[random_valence])-1)]\n",
    "            if word_to_add not in word_lists_dict[i] and word_lists_dict[i][-1] not in word_dict[random_valence] and \\\n",
    "               amt_positive <= amnt_wanted and amt_negative <= amnt_wanted and amt_neutral <= amnt_wanted:\n",
    "                if random_valence == \"positive\" and amt_positive < amnt_wanted:\n",
    "                    amt_positive += 1\n",
    "                elif random_valence == \"negative\" and amt_negative < amnt_wanted:\n",
    "                    amt_negative +=1\n",
    "                elif random_valence == \"neutral\" and amt_neutral < amnt_wanted:\n",
    "                    amt_neutral +=1\n",
    "                else:\n",
    "                    continue # skip this loop iteration\n",
    "                word_lists_dict[i].append(word_to_add)\n",
    "                \n",
    "    #convert the list to dictionary \n",
    "    word_indices_dict[i] = dict(zip(list(range(list_length)),word_lists_dict[i]))\n",
    "    all_unique_words.update(word_lists_dict[i])\n",
    "    \n",
    "def create_lists(list_amount=3, list_length=2):\n",
    "    '''\n",
    "    Create the wordlists used during the free recall tasks \n",
    "    '''  \n",
    "    global word_lists_dict \n",
    "    print(f'Creating {list_amount} lists with {list_length} words.')\n",
    "    for i in range(list_amount):\n",
    "        print(f'List {i+1}/{list_amount} created!', end=\"\\r\")\n",
    "        add_words(i, list_length)\n",
    "\n",
    "    # Save the dictionary to a .pickle file, so we do not have to create the word lists everytime we run the model                    \n",
    "    file = open(f\"word_lists/word_lists_dict_{list_length}_{list_amount}.pickle\",\"wb\")\n",
    "    pickle.dump(word_lists_dict, file)\n",
    "    file.close()\n",
    "    return word_lists_dict\n",
    "\n",
    "# Check if the word lists already exist, else create new word lists\n",
    "def check_and_create_lists():\n",
    "    global word_lists_dict\n",
    "    try:\n",
    "        file = open(f\"word_lists/word_lists_dict_{list_length}_{list_amount}.pickle\",\"rb\")\n",
    "        #file = open(f\"word_lists_dict_100_items_only.pickle\",\"rb\")\n",
    "        word_lists_dict = pickle.load(file)\n",
    "        for k,v in word_lists_dict.items():\n",
    "            #print(k,v)\n",
    "            word_indices_dict[k] = dict(zip(list(range(list_length)),v))\n",
    "            all_unique_words.update(v)\n",
    "        #word_indices_dict[i] = dict(zip(list(range(list_length)),word_lists_dict[i]))\n",
    "        file.close()\n",
    "        print(\"\\nSuccesfully loaded the word lists!\\n\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"\\nCreating word lists!\\n\")\n",
    "        #amount_to_create = list_amount                              \n",
    "        word_lists_dict = create_lists(list_amount,list_length)\n",
    "\n",
    "def display_word_lists():\n",
    "    '''\n",
    "    Display the word lists loaded/created\n",
    "    '''\n",
    "    for key, value in word_lists_dict.items():\n",
    "        print(f'List {key}:\\n {value}\\n')\n",
    "#     for key, value in word_indices_dict.items():\n",
    "#         print(f'List {key}:\\n {value}\\n')\n",
    "\n",
    "def close_exp_window():\n",
    "    '''\n",
    "    Close opened ACT-R window\n",
    "    '''\n",
    "    return actr.current_connection.evaluate_single(\"close-exp-window\")\n",
    "\n",
    "def prepare_for_recall(): \n",
    "    '''\n",
    "    Disable rehearsing productions, and clearing buffer contents to start the recalling phase \n",
    "    '''\n",
    "    disable_list = [\"rehearse-first\", \"rehearse-second\", \"rehearse-third\", \"rehearse-fourth\", \n",
    "                    \"rehearse-it\", \"skip-first\", \"skip-second\", \"skip-third\", \"skip-fourth\"]\n",
    "    for prod in disable_list:\n",
    "        actr.pdisable(prod)\n",
    "    actr.run(1, False) \n",
    "    for buff in [\"imaginal\", \"retrieval\", \"production\"]:\n",
    "        actr.clear_buffer(buff)  \n",
    "\n",
    "def setup_dm(word_list):\n",
    "    '''\n",
    "    Add words to declarative memory, since it can be assumed the test subjects know the English language already\n",
    "    '''\n",
    "    #print(\"\\n\\n############################################# Inside setup_dm i.e. Declarative Memory\")\n",
    "     \n",
    "    colour_conversion = {'pos': 'GREEN', 'neg': 'RED', 'neu': 'BLACK'}\n",
    "    for idx, word in enumerate(word_list):\n",
    "        valence = ''.join([char for char in word if not char.isdigit()])[:3]\n",
    "        actr.add_dm(('item'+str(idx), 'isa', 'memory', 'word', \"'\"+word+\"'\", 'valence', colour_conversion[valence]))\n",
    "#         if idx == 0:\n",
    "#             print(\"\\n Emaple of a chunk added in Declarative Memory is \\n\")\n",
    "#             print('item'+str(idx), 'isa', 'memory', 'word', \"'\"+word+\"'\", 'valence', colour_conversion[valence],\"\\n\")\n",
    "        \n",
    "\n",
    "def setup_experiment(human=True):\n",
    "    '''\n",
    "    Load the correct ACT-R model, and create a window to display the words\n",
    "    '''\n",
    "#     print(\"\\n\\n############################################# Inside setup_experiment\")\n",
    "#     print(f'\\nSubject = {subject}\\n')  \n",
    "\n",
    "    loaded = None\n",
    "    if subject == \"controls\":\n",
    "        loaded = actr.load_act_r_model(\"C:/Users/brata/Desktop/free_recall_cognitive_models/fyrp/csm_free_recall_model_v1.lisp\")\n",
    "    elif subject == \"depressed\":\n",
    "        loaded = actr.load_act_r_model(\"C:/Users/brata/Desktop/free_recall_cognitive_models/fyrp/csm_free_recall_model_depressed.lisp\")\n",
    "\n",
    "    #print(\"\\n\\n############################################# Inside setup_experiment\")\n",
    "    #print(f'\\nLoaded Act-r model = {loaded}\\n')  \n",
    "\n",
    "\n",
    "\n",
    "    window = actr.open_exp_window(\"Free Recall Experiment\", width=1024, height=768, visible=human) # 15inch resolution window\n",
    "    actr.install_device(window) \n",
    "    return window    \n",
    "\n",
    "def record_words_recalled(item):\n",
    "    '''\n",
    "    Register which words were recalled during the experiment for a specific wordlist and strip the numbers\n",
    "    '''\n",
    "    #print(f\"in record_words_recalled, the item is {item}\")\n",
    "    valence = ''.join(char for char in item if not char.isdigit())\n",
    "    item_idx = ''.join(char for char in item if char.isdigit())\n",
    "    recalled_words[current_list].append((valence, item_idx))\n",
    "\n",
    "def record_words_rehearsed(item):\n",
    "    '''\n",
    "    Register amount of rehearsals per word for each wordlist\n",
    "    '''\n",
    "    rehearsed_words[current_list][item] += 1\n",
    "\n",
    "def create_lplot(idx, xlabel, ylabel, x, y, xticks_len, filename, ytick_range=None, show=False):\n",
    "    '''\n",
    "    Create line plot using matplotlib\n",
    "    '''\n",
    "    plt.figure(idx)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.plot(x, y)\n",
    "    plt.xticks(np.arange(0, xticks_len, 1)) \n",
    "    plt.yticks(ytick_range)\n",
    "    plt.savefig(\"images/\"+subject+\"_\"+filename, bbox_inches='tight')\n",
    "    if show:\n",
    "        plt.show()    \n",
    "\n",
    "        \n",
    "def create_result_dict():\n",
    "    '''\n",
    "    Use a module-level function, instead of lambda function, to enable pickling it\n",
    "    '''\n",
    "    return defaultdict(int)\n",
    "\n",
    "\n",
    "def modify_recalled_words_for_lag(recalled_words):\n",
    "    \"\"\"\n",
    "    return joined values in recalled words dictionaries\n",
    "    \n",
    "    Ex: ('negative',781) ==> negative781\n",
    "    \"\"\"\n",
    "    modified_recalled_words = defaultdict(list)\n",
    "    for k,vals in recalled_words.items():\n",
    "        #temp =[]\n",
    "        for v in set(vals):\n",
    "            #temp.append(\"\".join(v))\n",
    "            #print(\"temp\",temp)\n",
    "            modified_recalled_words[k].append(\"\".join(v))\n",
    "    #print(\"mod\",modified_recalled_words)\n",
    "    return modified_recalled_words\n",
    "\n",
    "def calculate_lag(word_indices_dict, modified_recalled_words):\n",
    "    \"\"\"\n",
    "    We are calculating the lag for each list and each recall.\n",
    "    Extra_list_intrusions and repeated recalls are ignored in the calculations\n",
    "    First verify that recall is happening after every list.\n",
    "    \n",
    "    \"\"\"\n",
    "    global extra_list_intrusions\n",
    "    #print(word_indices_dict,recalled_words)\n",
    "    #for i in range(list_amount):\n",
    "        \n",
    "    #check ith list recalled words and indices\n",
    "    lags = defaultdict(list)\n",
    "    for k,vals in modified_recalled_words.items():\n",
    "        \n",
    "        #print(\"vals in this k\", k, vals, word_indices_dict[k])\n",
    "        for j in range(1,len(vals)):\n",
    "            #print(\"testing recall\",vals[j],word_indices_dict[k])\n",
    "            if vals[j] in word_indices_dict[k].values() and vals[j-1] in word_indices_dict[k].values():\n",
    "                #print(\"INsiiiide\")\n",
    "                current_index = list(word_indices_dict[k].keys())[list(word_indices_dict[k].values()).index(vals[j])]\n",
    "                prev_index = list(word_indices_dict[k].keys())[list(word_indices_dict[k].values()).index(vals[j-1])]\n",
    "                #print(\"indices\" ,current_index,prev_index)\n",
    "                lags[k].append(current_index - prev_index)\n",
    "            if vals[j] not in word_indices_dict[k].values() and vals[j] in all_unique_words:\n",
    "                extra_list_intrusions += 1\n",
    "                continue\n",
    "    #print(\"lagsssss\",lags)           \n",
    "    return lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating different pickle files to store results from multiple hyper-parameter values.\n",
    "def analysis(wlist_amount, show_plots=False):\n",
    "    '''\n",
    "    Review results of the recall experiment\n",
    "    '''\n",
    "    global results\n",
    "    result_dict = defaultdict(create_result_dict) # instead of defaultdict(lambda: defaultdict(int))\n",
    "    first_recall = defaultdict(int)\n",
    "    recall_probability = defaultdict(int)\n",
    "    rehearse_frequency = defaultdict(int)\n",
    "    transitions_amnt = 0\n",
    "    thought_train_len = []\n",
    "\n",
    "    for key, val in recalled_words.items():\n",
    "        thought_train_len.extend([(k, sum(1 for _ in count)) for k, count in groupby([val[0] for val in val[2:]])])\n",
    "        for idx, (retrieved_word, item_num) in enumerate(val[2:]):\n",
    "            if idx != 0:\n",
    "                if retrieved_word != val[2:][idx-1][0]:\n",
    "                    transitions_amnt += 1/wlist_amount # average over word lists\n",
    "\n",
    "    print(f'Avg. Amount of recall transitions = {int(transitions_amnt)}')\n",
    "    neg_thought_train_len = 0\n",
    "    neg_divider = 0.0001\n",
    "    for x in thought_train_len:\n",
    "        if x[0] == 'negative':\n",
    "            neg_divider += 1\n",
    "            neg_thought_train_len += x[1]\n",
    "    print(f'Avg. Negative Thought train length = {round(neg_thought_train_len/neg_divider, 3)}')            \n",
    "\n",
    "    for list_num, wlist in word_lists_dict.items():\n",
    "        if list_num < wlist_amount:\n",
    "            for key, val in recalled_words.items():\n",
    "                if key==list_num:\n",
    "                    first_recall[wlist.index(''.join(val[0]))] += 1   \n",
    "                    for idx, word in enumerate(wlist):\n",
    "                        first_recall[idx] += 0\n",
    "                        if ((''.join(char for char in word if not char.isdigit()), \n",
    "                             ''.join(char for char in word if char.isdigit()))) in val:\n",
    "                            recall_probability[idx] += 1\n",
    "                        else:\n",
    "                            recall_probability[idx] += 0                            \n",
    "                for retrieved_word, item_num in val[2:4]:\n",
    "                    result_dict[\"pstart\"][retrieved_word] += 1  \n",
    "                for retrieved_word, item_num in val[4:-2]:\n",
    "                    result_dict[\"pstay\"][retrieved_word] += 1\n",
    "                for retrieved_word, item_num in val[-2:]:\n",
    "                    result_dict[\"pstop\"][retrieved_word] += 1                                                        \n",
    "            for key, val in rehearsed_words.items():\n",
    "                if key==list_num:\n",
    "                    for idx, word in enumerate(wlist):\n",
    "                        rehearse_frequency[idx] += rehearsed_words[key][word]\n",
    "    \n",
    "    for key, val in first_recall.items():\n",
    "        first_recall[key] = val/wlist_amount\n",
    "\n",
    "    for key, val in recall_probability.items():\n",
    "        recall_probability[key] = val/wlist_amount\n",
    "\n",
    "    for key, val in rehearse_frequency.items():\n",
    "        rehearse_frequency[key] = val/wlist_amount      \n",
    "        \n",
    "    \n",
    "\n",
    "    xticks_len = len(word_lists_dict[0])\n",
    "    \n",
    "    \n",
    "    #results['x']['data'].append(range(len(word_lists_dict[0])))\n",
    "    #results['xticks_len']['data'].append(len(word_lists_dict[0]) )\n",
    "    results['rehearse_frequency']['data'] = list(rehearse_frequency.values())\n",
    "    results['recall_probability']['data'] = list(recall_probability.values())\n",
    "    results['first_recall']['data'] = list(first_recall.values()) \n",
    "    \n",
    "    with open(filename, 'w') as outfile:\n",
    "        json.dump(results, outfile)\n",
    "        \n",
    "    create_lplot(0, 'Serial input position', 'Rehearse Frequency', range(len(word_lists_dict[0])), list(rehearse_frequency.values()), \n",
    "                xticks_len, f'rehearse_frequency_{list_length}_{list_amount}_{rehearsal_time}_{recall_time}_{delay}.png', None, show_plots)\n",
    "\n",
    "    create_lplot(1, 'Serial input position', 'Starting Recall', range(len(word_lists_dict[0])), list(first_recall.values()), \n",
    "                xticks_len, f'starting_recall_{list_length}_{list_amount}_{rehearsal_time}_{recall_time}_{delay}.png', np.arange(0, .5, .1), show_plots)                \n",
    "\n",
    "    create_lplot(2, 'Serial input position', 'Recall Probability', range(len(word_lists_dict[0])), list(recall_probability.values()), \n",
    "                xticks_len, f'recall_probability_{list_length}_{list_amount}_{rehearsal_time}_{recall_time}_{delay}.png', np.arange(0, 1, .1), show_plots)   \n",
    "    \n",
    "#     create_lplot(3, 'Serial input position', 'Accuracy', range(len(word_lists_dict[0])), list(recall_accuracy.values()), \n",
    "#                 xticks_len, 'recall_accuracy.png', np.arange(0, 1, .1), show_plots) \n",
    "\n",
    "    file = open(\"results_\"+subject+\".pickle\",\"wb\")\n",
    "    pickle.dump(result_dict, file)\n",
    "    file.close()\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_experiment(subj=\"depressed\", human=False, wlist_amount=20):\n",
    "    '''\n",
    "    Run the experiment\n",
    "    '''\n",
    "    check_and_create_lists()\n",
    "    global subject,word_lists_dict\n",
    "    subject = subj\n",
    "    assert wlist_amount <= len(word_lists_dict), \"Chosen too many lists, choose less or create more word lists using function: create_lists()\"\n",
    "    \n",
    "#     print(\"###################################################\\n\")\n",
    "#     print(\"The original word list \\n\")\n",
    "#     print(display_word_lists())\n",
    "   \n",
    "    \n",
    "#     print(\"\\n###################################################\\n\")\n",
    "#     print(\"Experiment started, Trying to understand the flow\\n\")\n",
    "  \n",
    "    for idx, (key, value) in enumerate(word_lists_dict.items()):\n",
    "        actr.reset()\n",
    "        window = setup_experiment(human)\n",
    "        global current_list\n",
    "        current_list = idx # keep track for which list words are recalled\n",
    "        setup_dm(value)   \n",
    "        actr.add_command(\"retrieved-word\", record_words_recalled,\"Retrieves recalled words.\")\n",
    "        actr.add_command(\"rehearsed-word\", record_words_rehearsed,\"Retrieves rehearsed words.\")\n",
    "#         print(\"\\n##################  Model started rehearsal \")\n",
    "        for word in value:\n",
    "            if \"neutral\" in word:\n",
    "                color = \"black\"\n",
    "            elif \"positive\" in word:\n",
    "                color = \"green\"\n",
    "            else:\n",
    "                color = \"red\"\n",
    "            actr.add_text_to_exp_window(window, word, x=475-len(word) , y=374, color=color, font_size=20) # change later \n",
    "            actr.run(rehearsal_time, human) # True when choosing Human, False when choosing differently\n",
    "            actr.clear_exp_window(window)\n",
    "            actr.run(delay, human)  # 500-ms blank screen                        \n",
    "        prepare_for_recall()       \n",
    "        actr.remove_command(\"rehearsed-word\")\n",
    "#         print(\"\\n##################  Model finished rehearsal, list of rehearsed words is \")\n",
    "#         print(f'{rehearsed_words}\\n')\n",
    "#         print(\"\\n##################  Model started recall \")\n",
    "        actr.goal_focus(\"startrecall\") # set goal to start recalling\n",
    "        actr.run(recall_time, human)  \n",
    "        actr.remove_command(\"retrieved-word\")\n",
    "\n",
    "        print(f'Experiment {idx+1}/{wlist_amount} completed!', end=\"\\r\")\n",
    "        #print(\"\\n##################  Model finished recall, list of recalled words is \")\n",
    "        #print(f'{recalled_words}\\n')\n",
    "        if idx == wlist_amount-1: # run for a chosen amount of word lists\n",
    "            break\n",
    "    close_exp_window() # close window at end of experiment     \n",
    "\n",
    "    avg_recalled, avg_recalled_unique = 0, 0\n",
    "    for key, val in recalled_words.items():\n",
    "        avg_recalled += len(val)\n",
    "        avg_recalled_unique += len(set(val))\n",
    "    #    print(f'\\nList {key} (length={len(val)}, unique={len(set(val))})')\n",
    "    print(f'Avg. Amount of words recalled = {avg_recalled//wlist_amount}')\n",
    "    print(f'Avg. Amount of unique words recalled = {avg_recalled_unique//wlist_amount}')\n",
    "    \n",
    "    #print(f'recalled words {recalled_words}')\n",
    "    \n",
    "#     result = analysis(list_amount, False)        \n",
    "\n",
    "#     for key, val in result.items():\n",
    "#         print(f'{key} = {dict(val)}')\n",
    "#     print()\n",
    " \n",
    "\n",
    "#     print(\"\\n\\n#############################################\")\n",
    "#     print(f'\\n[{subj}] Results!\\n')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_possible_lags(list_length):\n",
    "    \"\"\"\n",
    "    Given the list length we will count all the possible lags by calculating the pairs for each lag\n",
    "    \"\"\"\n",
    "    possible_lags = list(combinations(list(range(list_length)),2))\n",
    "    #print(possible_lags,len(possible_lags))\n",
    "    possible_lags_count = defaultdict(int)\n",
    "#     possible_lags_count[0] = 0\n",
    "#     possible_lags_count[1] = list_length-1\n",
    "#     possible_lags_count[-1] = list_length-1\n",
    "    \n",
    "    for lag in possible_lags:\n",
    "        possible_lags_count[lag[0]-lag[1]] += 1\n",
    "        possible_lags_count[lag[1]-lag[0]] += 1\n",
    "        #possible_lags_count[-lag] += math.floor(list_length/lag)\n",
    "    return possible_lags_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitSerToArr(ser):\n",
    "    return [ser.index, ser.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(cummulative_lags):\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    x_vals = list(cummulative_lags.keys())\n",
    "    y_vals = list(cummulative_lags.values())\n",
    "    x_vals_pos = []\n",
    "    y_vals_pos = []\n",
    "    x_vals_neg = []\n",
    "    y_vals_neg = []\n",
    "    # Dividing the lists into two parts negative and positive to achieve the curves style in Kahana\n",
    "    for i in range(len(x_vals)):\n",
    "        if x_vals[i]<0:\n",
    "            x_vals_neg.append(x_vals[i])\n",
    "            if y_vals[i]!=0:\n",
    "                y_vals_neg.append(y_vals[i])\n",
    "            else:\n",
    "                y_vals_neg.append(None)\n",
    "        elif x_vals[i]>0:\n",
    "            x_vals_pos.append(x_vals[i])\n",
    "            if y_vals[i]!=0:\n",
    "                y_vals_pos.append(y_vals[i])\n",
    "            else:\n",
    "                y_vals_pos.append(None)\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "#labels = ['Geeks1', 'Geeks2', 'Geeks3', 'Geeks4'] \n",
    "    #Converting the arrays in Series(pandas) to convert 0's to NaNs so that they are not plotted\n",
    "    s_pos = pd.Series(y_vals_pos, index=(x_vals_pos))\n",
    "    s_neg = pd.Series(y_vals_neg, index=(x_vals_neg))\n",
    "    #plt.plot( *splitSerToArr(s_pos.dropna()), linestyle='-', marker='o')\n",
    "    plt.ylabel('Conditional Response Probability')\n",
    "    plt.xlabel('Lags values (ranging from -list_length+1 to list_length-1)')\n",
    "    #plt.grid(True)\n",
    "    plt.ylim((0,1))\n",
    "    #plt.xticks(list(range(-list_length+1,list_length,1)))\n",
    "    #plt.margins(0) \n",
    "    # Tweak spacing to prevent clipping of tick-labels \n",
    "    plt.subplots_adjust(bottom = 0.15)\n",
    "    ax.plot(*splitSerToArr(s_pos.dropna()), '-o')\n",
    "    ax.plot(*splitSerToArr(s_neg.dropna()), '-o')\n",
    "    ax.set_xticks(list(range(-list_length+1,list_length,1)))\n",
    "    plt.savefig(f\"lag_crp_plots_postman/delay_{delay}/single_experiment_lag_crp_words_{list_length}_lists_{list_amount}.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crp = {0: {-7: 0.25, -1: 0.1}, 1: {-9: 0.5}}\n",
    "# dict_keys = list(range(-list_length+1,list_length))\n",
    "# dict_val = 0\n",
    "# cummulative_lags = dict.fromkeys(dict_keys,dict_val)\n",
    "\n",
    "# for value in range(-list_length+1,list_length): #key corresponds to number of lists and vals are the lags inside each list\n",
    "#     value_count = 0 # Number of times this lag occured in all lists\n",
    "#     for k,v in crp.items(): #k represents different lags that occur\n",
    "#         #print(\"k, \",k,crp[k].keys())\n",
    "#         if value in crp[k].keys():\n",
    "#             value_count+=1\n",
    "#             cummulative_lags[value] += crp[k][value]\n",
    "#     if value_count!=0:\n",
    "#         cummulative_lags[value] /= value_count\n",
    "# print(\"Cummulative lags\", cummulative_lags)\n",
    "# #Cummulative lags defaultdict(<class 'int'>, {-10: 0, -9: 0.5, -8: 0, -7: 0.0, -6: 0, -5: 0, -4: 0, -3: 0, -2: 0, -1: 0.0, 0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_lag_crp(lags):\n",
    "    \"\"\"\n",
    "    Calculates average lags across all the lists \n",
    "    Response probability is calculated by the number_of_transtions of the lag/total transitions possible of the lag\n",
    "    Note: Total Transitions does not count the extra_list_intrusions or repeated recalls\n",
    "    \"\"\"\n",
    "    # Gets dictionary containing total possible lags in the list of length list_length.\n",
    "    possible_lags_count = count_possible_lags(list_length)\n",
    "    #print(\"received\",lags)\n",
    "    crp = defaultdict(dict)\n",
    "    for key,vals in lags.items():\n",
    "        #lags that occured in the current list\n",
    "        #count the different lags in the lags list\n",
    "        counts = Counter(vals)\n",
    "        for k,v in counts.items():\n",
    "            crp[key][k] = v/possible_lags_count[k]\n",
    "    #print(\"CRP \", crp)\n",
    "    dict_keys = list(range(-list_length+1,list_length))\n",
    "    dict_val = 0\n",
    "    cummulative_lags = dict.fromkeys(dict_keys,dict_val)\n",
    "    for value in range(-list_length+1,list_length): #key corresponds to number of lists and vals are the lags inside each list\n",
    "        value_count = 0 # Number of times this lag occured in all lists\n",
    "        for k,v in crp.items(): #k represents different lags that occur\n",
    "            if value in crp[k].keys():\n",
    "                value_count+=1\n",
    "                cummulative_lags[value] += crp[k][value]\n",
    "        if value_count!=0:\n",
    "            cummulative_lags[value] /= value_count\n",
    "    #print(\"Cummulative lags\", cummulative_lags)\n",
    "    #print(\"crps\", crp)\n",
    "    #plot(cummulative_lags)\n",
    "    return cummulative_lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Started for agent_0\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'lag_crp_plots_postman/delay_0'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-43ec56e77a36>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"------------------------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Started for agent_{agent}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mdo_experiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'controls'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlist_amount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#     print(\"indices\",word_indices_dict)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-bb5bf72606e8>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(iteration)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'lag_crp_plots_postman/delay_{delay}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'lag_crp_plots_postman/delay_{delay}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;31m#     if not os.path.exists(f'./lag_crp_plots/delay_{delay}/words_{list_length}'):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'lag_crp_plots_postman/delay_0'"
     ]
    }
   ],
   "source": [
    "num_agents = 30\n",
    "cummulative_lags_all_agents = []\n",
    "for agent in range(num_agents):\n",
    "    print(\"------------------------------\")\n",
    "    print(f\"Started for agent_{agent}\")\n",
    "    __init__(agent)\n",
    "    do_experiment('controls',False,list_amount)\n",
    "#     print(\"indices\",word_indices_dict)\n",
    "#     print(\"------------------------------\")\n",
    "#     print(\"------------------------------\")\n",
    "    modified_recalled_words = modify_recalled_words_for_lag(recalled_words)\n",
    "#     print(\"recalled_words\",modified_recalled_words)\n",
    "#     print(\"------------------------------\")\n",
    "#     print(\"------------------------------\")\n",
    "    #print(all_unique_words)\n",
    "    lags = calculate_lag(word_indices_dict, modified_recalled_words)\n",
    "    #print(word_indices_dict)\n",
    "    #print(recalled_words)\n",
    "    #print(lags)\n",
    "    cummulative_lags_all_agents.append(calculate_lag_crp(lags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['lag_crps']['data'] = cummulative_lags_all_agents\n",
    "with open(filename, 'w') as outfile:\n",
    "    json.dump(results, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_calculate_lag(word_indices_dict, modified_recalled_words):\n",
    "#     \"\"\"\n",
    "#     We are calculating the lag for each list and each recall.\n",
    "#     Extra_list_intrusions and repeated recalls are ignored in the calculations\n",
    "#     First verify that recall is happening after every list.\n",
    "    \n",
    "#     \"\"\"\n",
    "#     global extra_list_intrusions\n",
    "#     #print(word_indices_dict,recalled_words)\n",
    "#     #for i in range(list_amount):\n",
    "        \n",
    "#     #check ith list recalled words and indices\n",
    "#     lags = defaultdict(list)\n",
    "#     for k,vals in modified_recalled_words.items():\n",
    "        \n",
    "#         #print(\"vals in this k\", k, vals, word_indices_dict[k])\n",
    "#         for j in range(1,len(vals)):\n",
    "#             print(\"testing recall\",vals[j],vals[j-1])\n",
    "#             if vals[j] in word_indices_dict[k].values() and vals[j-1] in word_indices_dict[k].values():\n",
    "#                 #print(\"INsiiiide\")\n",
    "#                 current_index = list(word_indices_dict[k].keys())[list(word_indices_dict[k].values()).index(vals[j])]\n",
    "#                 prev_index = list(word_indices_dict[k].keys())[list(word_indices_dict[k].values()).index(vals[j-1])]\n",
    "#                 print(\"indices\" ,current_index,prev_index)\n",
    "#                 lags[k].append(current_index - prev_index)\n",
    "#             if vals[j] not in word_indices_dict[k].values() and vals[j] in all_unique_words:\n",
    "#                 extra_list_intrusions += 1\n",
    "#                 continue\n",
    "#     #print(\"lagsssss\",lags)           \n",
    "#     return lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_indices_dict = {0: {0: 'neutral732', 1: 'neutral886', 2: 'negative209', 3: 'positive991', 4: 'neutral146', 5: 'positive53', \n",
    "#                         6: 'negative459', 7: 'positive940', 8: 'neutral547', 9: 'negative582', 10: 'neutral142'}, \n",
    "#                     1: {0: 'neutral346', 1: 'neutral464', 2: 'negative683', 3: 'neutral982', 4: 'negative661', 5: 'neutral712',\n",
    "#                         6: 'positive289', 7: 'negative560', 8: 'positive636', 9: 'neutral933', 10: 'positive634'}}\n",
    "\n",
    "# m_recalled_words = {0: [('positive', '53'), ('positive', '53'), ('negative', '582'), ('neutral', '346'), ('positive', '636'), ('neutral', '712')], \n",
    "#                   1: [('positive', '53'), ('positive', '53'), ('negative', '582'), ('neutral', '346'), ('positive', '636'), ('neutral', '712')]}\n",
    "\n",
    "# mod_recalled_words = modify_recalled_words_for_lag(m_recalled_words)\n",
    "\n",
    "# print(\"recalled words \",mod_recalled_words)\n",
    "# lags = test_calculate_lag(word_indices_dict, mod_recalled_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
