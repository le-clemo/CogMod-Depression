{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import actr\n",
    "import pickle\n",
    "import random\n",
    "import os\n",
    "import fnmatch\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from itertools import groupby\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observed Issues:\n",
    "(see file \"current_issues\")\n",
    "\n",
    "- Recency effect still too weak.\n",
    "\n",
    "- Primacy effect too strong.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of words in each list i.e. list_length should be n where (n-2)%3 == 0 because 2 neutral words are added in each list.\n",
    "\n",
    "#### The adjustable parameters in this experiment code.\n",
    "    - number of agents (top of next cell)\n",
    "    - experimental conditions (further below) --> multiple conditions can be set in a list of lists [[rehearsal time1, num words per list 1], [rehearsal time 2, num words per list 2], ...]\n",
    "    - Number of lists (further below)\n",
    "#### Adjustable parameters in ACT-R\n",
    "    - :declarative-num-finsts 21 ; number of items that are kept as recently retrieved (Change it to 5) \n",
    "    - :declarative-finst-span 21 ; how long items stay in the recently-retrieved state (5,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(actr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Experiment part ###\n",
    "\n",
    "def __init__(iteration, rehearsal_time, list_length, list_amount=3, path=\".\", rum_chunks=0):\n",
    "    subject = ''\n",
    "\n",
    "    current_list = ''\n",
    "    \n",
    "    associated_list = ''\n",
    "\n",
    "    recalled_words = defaultdict(list)\n",
    "\n",
    "    rehearsed_words =  defaultdict(lambda: defaultdict(int))\n",
    "    \n",
    "    buffer_items = []\n",
    "\n",
    "    #list_amount = 3   # No of lists (100, 200, 1000, 2000 AND 5000)\n",
    "\n",
    "    #Set below where function is actually called\n",
    "    list_length = list_length   # No of words in a list\n",
    "    rehearsal_time = rehearsal_time  # No of seconds for which rehearsal happens and each word is shown\n",
    "\n",
    "    delay = 1  #delay between rehearsal and recall\n",
    "\n",
    "    recall_time = 90\n",
    "    \n",
    "    #distractor_time = 30 #set further below\n",
    "    \n",
    "    word_lists_dict = defaultdict(list)\n",
    "    wlist_for_analysis = defaultdict(list) #without buffer words\n",
    "    \n",
    "    # Ensure there are enough unique words to create the word lists\n",
    "    word_dict = {\"positive\": [\"positive\" + str(i) for i in range(999)],\n",
    "                 \"negative\": [\"negative\" + str(i) for i in range(999)],\n",
    "                 \"neutral\": [\"neutral\" + str(i) for i in range(999)]}\n",
    "\n",
    "    filename = f'{path}\\words_{list_length}_lists_{list_amount}_{condition}_rh_time_{rehearsal_time}_rec_time_{recall_time}_delay_{delay}_{iteration}.txt'\n",
    "    \n",
    "    results = {}\n",
    "\n",
    "    results['x'] = {'data': [], # will be appended later in the analytics function\n",
    "                          'info': \"Storing range(len(word_lists_dict[0])) here\"}\n",
    "\n",
    "    results['rehearse_frequency'] = {'data': None,# will be appended later in the analytics function\n",
    "                                     'info': \"Storing list(rehearse_frequency.values()) here\"}\n",
    "\n",
    "    results['recall_probability'] = {'data': None, # will be appended later in the analytics function\n",
    "                                        'info': \"Storing list(recall_probability.values()) here\"}\n",
    "\n",
    "    results['first_recall'] = {'data': None, # will be appended later in the analytics function\n",
    "                               'info': \"Storing list(first_probability.values()) here\"}\n",
    "    \n",
    "    results['pli'] = {'data': None, # will be appended later in the analytics function\n",
    "                         'info': \"Storing avg PLIs per agent here\"}\n",
    "    \n",
    "    results['transitions'] = {'data': None, # will be appended later in the analytics function\n",
    "                         'info': \"Storing recall transitions here\"}\n",
    "    \n",
    "    results['neg_thought_train'] = {'data': None, # will be appended later in the analytics function\n",
    "                         'info': \"Storing negative thought train lengths here\"}\n",
    "\n",
    "    with open(filename, 'w') as outfile:\n",
    "        json.dump(results, outfile)\n",
    "\n",
    "    with open(filename) as json_file:\n",
    "        results = json.load(json_file)\n",
    "#         #print(results)\n",
    "    \n",
    "    globals().update(locals())  ## Making everything public, worst code you can ever write!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_words(i, list_length):\n",
    "    '''\n",
    "    Add the words to the word lists, ensures valence categories are balanced\n",
    "    '''\n",
    "    global word_lists_dict\n",
    "\n",
    "    amnt_wanted = list_length/3 # Amount of each valence wanted, minus 2 neutrals controlling for primacy\n",
    "    amt_positive, amt_negative, amt_neutral, count = 0, 0, 0, 0\n",
    "    while len(word_lists_dict[i]) != list_length:\n",
    "        count += 1\n",
    "        #print(f\"...................{count,word_lists_dict[i]}\")\n",
    "        if count >= 9999: # IF it takes too long to create a unique list at random, start over\n",
    "            word_lists_dict[i] = []\n",
    "            add_words(i, list_length)\n",
    "        if len(word_lists_dict[i]) == 0: # Place two neutral words at the start to control for primacy effects\n",
    "            word_to_add1 = word_dict[\"neutral\"][random.randint(0, len(word_dict[\"neutral\"])-1)]\n",
    "            word_to_add2 = word_dict[\"neutral\"][random.randint(0, len(word_dict[\"neutral\"])-1)]\n",
    "            if word_to_add1 not in word_lists_dict[i] and word_to_add2 not in word_lists_dict[i] and word_to_add1 != word_to_add2:\n",
    "                word_lists_dict[i].append(word_to_add1)\n",
    "                word_lists_dict[i].append(word_to_add2) \n",
    "                \n",
    "#             else:\n",
    "#                 continue # skip this loop iteration\n",
    "       \n",
    "    ### only for vanVugt\n",
    "        elif len(word_lists_dict[i]) == 20: # Place two neutral words at the start to control for primacy effects\n",
    "            word_to_add3 = word_dict[\"neutral\"][random.randint(0, len(word_dict[\"neutral\"])-1)]\n",
    "            word_to_add4 = word_dict[\"neutral\"][random.randint(0, len(word_dict[\"neutral\"])-1)]\n",
    "            if word_to_add3 not in word_lists_dict[i] and word_to_add4 not in word_lists_dict[i] and word_to_add3 != word_to_add4:\n",
    "                word_lists_dict[i].append(word_to_add3)\n",
    "                word_lists_dict[i].append(word_to_add4)        \n",
    "                \n",
    "            else:\n",
    "                continue # skip this loop iteration                   \n",
    "        else: \n",
    "            random_valence = random.choice([\"positive\", \"negative\", \"neutral\"])\n",
    "            word_to_add = word_dict[random_valence][random.randint(0, len(word_dict[random_valence])-1)]\n",
    "            if word_to_add not in word_lists_dict[i] and word_lists_dict[i][-1] not in word_dict[random_valence] and \\\n",
    "               amt_positive <= amnt_wanted and amt_negative <= amnt_wanted and amt_neutral <= amnt_wanted:\n",
    "                if random_valence == \"positive\" and amt_positive < amnt_wanted:\n",
    "                    amt_positive += 1\n",
    "                elif random_valence == \"negative\" and amt_negative < amnt_wanted:\n",
    "                    amt_negative +=1\n",
    "                elif random_valence == \"neutral\" and amt_neutral < amnt_wanted:\n",
    "                    amt_neutral +=1\n",
    "                else:\n",
    "                    continue # skip this loop iteration\n",
    "                word_lists_dict[i].append(word_to_add)\n",
    "\n",
    "def create_lists(list_amount=3, list_length=2):\n",
    "    '''\n",
    "    Create the wordlists used during the free recall tasks \n",
    "    '''  \n",
    "    global word_lists_dict \n",
    "\n",
    "    for i in range(list_amount):\n",
    "        print(f'List {i+1}/{list_amount} created!', end=\"\\r\")\n",
    "        add_words(i, list_length)\n",
    "\n",
    "    # Save the dictionary to a .pickle file, so we do not have to create the word lists everytime we run the model                    \n",
    "    file = open(f\"word_lists/word_lists_dict_{list_length}_{list_amount}.pickle\",\"wb\")\n",
    "    pickle.dump(word_lists_dict, file)\n",
    "    file.close()\n",
    "    return word_lists_dict\n",
    "\n",
    "# Check if the word lists already exist, else create new word lists\n",
    "def check_and_create_lists():\n",
    "    global word_lists_dict\n",
    "    global wlist_for_analysis\n",
    "    global buffer_items\n",
    "    try:\n",
    "        file = open(f\"word_lists/word_lists_dict_{list_length}_{list_amount}.pickle\",\"rb\")\n",
    "        #file = open(f\"word_lists_dict_100_items_only.pickle\",\"rb\")\n",
    "        word_lists_dict = pickle.load(file)  \n",
    "        file.close()\n",
    "        print(\"\\nSuccesfully loaded the word lists!\\n\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"\\nCreating word lists!\\n\")\n",
    "        #amount_to_create = list_amount                              \n",
    "        word_lists_dict = create_lists(list_amount,list_length)\n",
    "    \n",
    "    wlist_for_analysis = word_lists_dict.copy()\n",
    "    for i in range(num_lists):\n",
    "        buffer_items.append(word_lists_dict[i][0])\n",
    "        buffer_items.append(word_lists_dict[i][1])\n",
    "        buffer_items.append(word_lists_dict[i][-2])\n",
    "        buffer_items.append(word_lists_dict[i][-1])\n",
    "    \n",
    "    #remove buffer words for analysis\n",
    "    for key, value in wlist_for_analysis.items():\n",
    "        wlist_for_analysis[key] = value[2:20]\n",
    "        \n",
    "        \n",
    "def display_word_lists():\n",
    "    '''\n",
    "    Display the word lists loaded/created\n",
    "    '''\n",
    "    for key, value in word_lists_dict.items():\n",
    "        print(f'List {key}:\\n {value}\\n')\n",
    "\n",
    "def close_exp_window():\n",
    "    '''\n",
    "    Close opened ACT-R window\n",
    "    '''\n",
    "    return actr.current_connection.evaluate_single(\"close-exp-window\")\n",
    "\n",
    "\n",
    "def prepare_for_memorization():\n",
    "    '''\n",
    "    Enable rehearsing productions to start the memorization phase \n",
    "    '''    \n",
    "    \n",
    "    #actr.run(1, False)\n",
    "    \n",
    "    enable_list = [\"rehearse-first\", \"rehearse-second\", \"rehearse-third\", \"rehearse-fourth\", \n",
    "                    \"rehearse-first-default\", \"rehearse-second-default\", \"rehearse-third-default\",\n",
    "                    \"rehearse-fourth-default\", \"rehearse-it\", \"rehearse-it-wrong-word\", \"skip-rehearse-1\",\n",
    "                    \"skip-rehearse-2\", \"skip-rehearse-3\", \"skip-rehearse-4\", \"attend-new-word\",\n",
    "                    \"initiate-rumination\", \"continue-rumination-1\", \"continue-rumination-2\",\n",
    "                    \"wait-1\", \"wait-2\", \"wait-3\", \"wait-4\", \"ruminate\", \"finish-recall-1\",\n",
    "                   \"finish-recall-2\"]\n",
    "    \n",
    "    disable_list = [\"retrieve-a-word\", \"recall-a-word\", \"stop-recall\", \"ruminate\"]\n",
    "    \n",
    "    for prod in disable_list:\n",
    "        actr.pdisable(prod)\n",
    "        \n",
    "    for prod in enable_list:\n",
    "        actr.penable(prod)   \n",
    "    \n",
    "    actr.goal_focus(\"goal\") # set goal to start memorization\n",
    "    \n",
    "    for buff in [\"imaginal\", \"retrieval\", \"production\"]:\n",
    "        actr.clear_buffer(buff)  \n",
    "    \n",
    "    #actr.run(1, False)\n",
    "    \n",
    "    for buff in [\"imaginal\", \"retrieval\", \"production\"]:\n",
    "        actr.clear_buffer(buff)\n",
    "\n",
    "    \n",
    "def prepare_for_recall(distractor=0): \n",
    "    '''\n",
    "    Disable rehearsing productions, and clearing buffer contents to start the recalling phase \n",
    "    '''\n",
    "    if distractor: #disable distractor or memorization PRs\n",
    "        \n",
    "        disable_list = [\"crowd-out-wm\", \"continue-task\"]\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        disable_list = [\"rehearse-first\", \"rehearse-second\", \"rehearse-third\", \"rehearse-fourth\", \n",
    "                        \"rehearse-first-default\", \"rehearse-second-default\", \"rehearse-third-default\",\n",
    "                        \"rehearse-fourth-default\", \"rehearse-it\", \"rehearse-it-wrong-word\", \"skip-rehearse-1\",\n",
    "                        \"skip-rehearse-2\", \"skip-rehearse-3\", \"skip-rehearse-4\", \"attend-new-word\",\n",
    "                       \"initiate-rumination\", \"continue-rumination-1\", \"continue-rumination-2\",\n",
    "                        \"wait-1\", \"wait-2\", \"wait-3\", \"wait-4\", \"ruminate\", \"finish-recall-1\",\n",
    "                       \"finish-recall-2\"]\n",
    "    \n",
    "    #enable list is the same either way\n",
    "    enable_list = [\"retrieve-a-word\", \"recall-a-word\", \"stop-recall\", \"ruminate\"]\n",
    "    \n",
    "    for prod in disable_list:\n",
    "        actr.pdisable(prod)\n",
    "\n",
    "    for prod in enable_list:\n",
    "        actr.penable(prod)\n",
    "        \n",
    "    actr.run(delay, False) \n",
    "    \n",
    "    for buff in [\"imaginal\", \"retrieval\", \"production\"]:\n",
    "        actr.clear_buffer(buff) \n",
    "        \n",
    "def prepare_for_distractor(): \n",
    "    '''\n",
    "    Disable rehearsing productions, and clearing buffer contents to start the distractor task \n",
    "    '''\n",
    "    disable_list = [\"rehearse-first\", \"rehearse-second\", \"rehearse-third\", \"rehearse-fourth\", \n",
    "                    \"rehearse-first-default\", \"rehearse-second-default\", \"rehearse-third-default\",\n",
    "                    \"rehearse-fourth-default\", \"rehearse-it\", \"rehearse-it-wrong-word\", \"skip-rehearse-1\",\n",
    "                  \"skip-rehearse-2\", \"skip-rehearse-3\", \"skip-rehearse-4\", \"attend-new-word\",\n",
    "                   \"initiate-rumination\", \"continue-rumination-1\", \"continue-rumination-2\",\n",
    "                   \"wait-1\", \"wait-2\", \"wait-3\", \"wait-4\", \"ruminate\", \"finish-recall-1\",\n",
    "                   \"finish-recall-2\"]\n",
    "    \n",
    "    enable_list = [\"crowd-out-wm\", \"continue-task\"]\n",
    "    \n",
    "    for prod in disable_list:\n",
    "        actr.pdisable(prod)\n",
    "\n",
    "    for prod in enable_list:\n",
    "        actr.penable(prod)\n",
    "        \n",
    "    actr.run(delay, False) \n",
    "    \n",
    "    for buff in [\"imaginal\", \"retrieval\", \"production\"]:\n",
    "        actr.clear_buffer(buff) \n",
    "\n",
    "def setup_dm(word_lists_dict, condition='controls', rumination_chunks=0, neg_bias=2.5):\n",
    "    '''\n",
    "    Add words to declarative memory, since it can be assumed the test subjects know the English language already\n",
    "    '''\n",
    "    #print(\"\\n\\n############################################# Inside setup_dm i.e. Declarative Memory\")\n",
    "    \n",
    "    rumination_list = []\n",
    "    if condition == 'depressed':\n",
    "        for i in range(rumination_chunks):\n",
    "            actr.add_dm(('rumination'+str(i), 'isa', 'memory', 'word', 'rumination'+str(i),\n",
    "                         'valence', 'RED', 'context', 'rumination')) #, 'type', 'rumination'\n",
    "            rumination_list.append(('rumination'+str(i)).upper())\n",
    "    \n",
    "        #set creation times and times of prior reference for each chunk  \n",
    "    actr.sdp(':reference-list', list(np.linspace(0, -1000, 600)), ':creation-time', -1000)\n",
    "    \n",
    "    neg_word_list = []\n",
    "    colour_conversion = {'pos': 'GREEN', 'neg': 'RED', 'neu': 'BLACK'}\n",
    "    for list_idx, word_list in word_lists_dict.items():\n",
    "        i = 0\n",
    "        for idx, word in enumerate(word_list):\n",
    "            valence = ''.join([char for char in word if not char.isdigit()])[:3]\n",
    "            #we have to first add only the negative words s.t. we can set the similarities with the rumination chunks via sdp (sdp would otherwise set the similarities for all chunks)\n",
    "            if valence == 'neg':\n",
    "                actr.add_dm((valence+str(i)+\"-\"+str(list_idx), 'isa', 'memory', 'word', \"'\"+word+\"'\", 'valence', colour_conversion[valence],\n",
    "                            'context', 'list'+str(list_idx), 'type', 'on-task')) #, 'type', 'on-task'\n",
    "                neg_word_list.append((valence+str(i)+\"-\"+str(list_idx).upper()))\n",
    "                i += 1\n",
    "                \n",
    "#     for chunk in rumination_list:  \n",
    "#         actr.sdp(':sjis', [[chunk, 1]])\n",
    "    \n",
    "#     for word in neg_word_list:  \n",
    "#         actr.sdp(':sjis', [[word, 1]])   \n",
    "    \n",
    "    if condition == 'depressed':\n",
    "        #adding connection strength to negative valence for negative words and rumination chunks\n",
    "        actr.sdp(':sjis', [['RED', neg_bias]])\n",
    "        \n",
    "        #adding chunks that relate to neutral and positive words, respectively. This is to ensure a balance in spreading activation\n",
    "        mindwandering_chunks = rumination_chunks//2\n",
    "        if mindwandering_chunks > 0:\n",
    "            for i in range(mindwandering_chunks):\n",
    "                actr.add_dm(('mindwandering'+str(i), 'isa', 'memory', 'word', 'mw'+str(i),\n",
    "                             'valence', 'BLACK', 'context', 'mindwandering')) #, 'type', 'mindwandering'\n",
    "\n",
    "        daydreaming_chunks = rumination_chunks//2\n",
    "        if daydreaming_chunks > 0:\n",
    "            for i in range(daydreaming_chunks):\n",
    "                actr.add_dm(('daydreaming'+str(i), 'isa', 'memory', 'word', 'dd'+str(i),\n",
    "                             'valence', 'GREEN', 'context', 'daydreaming')) #, 'type', 'daydreaming'\n",
    "    \n",
    "    #adding the remaining words (positive + neutral after setting connection strengths between rumination chunks and negative words)\n",
    "    for list_idx, word_list in word_lists_dict.items():\n",
    "        i, j = 0, 0\n",
    "        for idx, word in enumerate(word_list):\n",
    "            valence = ''.join([char for char in word if not char.isdigit()])[:3]\n",
    "            #we have to first add only the negative words s.t. we can set the similarities with the rumination chunks via sdp (sdp would otherwise set the similarities for all chunks)\n",
    "            if valence == 'pos':\n",
    "                actr.add_dm((valence+str(i)+\"-\"+str(list_idx), 'isa', 'memory', 'word', \"'\"+word+\"'\", 'valence', colour_conversion[valence],\n",
    "                            'context', 'list'+str(list_idx), 'type', 'on-task')) #, 'type', 'on-task'\n",
    "                i += 1\n",
    "            elif valence == 'neu':\n",
    "                actr.add_dm((valence+str(j)+\"-\"+str(list_idx), 'isa', 'memory', 'word', \"'\"+word+\"'\", 'valence', colour_conversion[valence],\n",
    "                            'context', 'list'+str(list_idx), 'type', 'on-task')) #, 'type', 'on-task'\n",
    "                j += 1\n",
    "                \n",
    "\n",
    "                \n",
    "    #         if idx == 0:\n",
    "    #             print(\"\\n Emaple of a chunk added in Declarative Memory is \\n\")\n",
    "    #             print('item'+str(idx), 'isa', 'memory', 'word', \"'\"+word+\"'\", 'valence', colour_conversion[valence],\"\\n\")\n",
    "\n",
    "    \n",
    "def setup_experiment(human=True):\n",
    "    '''\n",
    "    Load the correct ACT-R model, and create a window to display the words\n",
    "    '''\n",
    "#     print(\"\\n\\n############################################# Inside setup_experiment\")\n",
    "#     print(f'\\nSubject = {subject}\\n')  \n",
    "\n",
    "    loaded = None\n",
    "    if subject == \"controls\":\n",
    "        loaded = actr.load_act_r_model(r\"C:\\Users\\cleme\\Documents\\Education\\RUG\\First-Year_Research\\My_Project\\Model\\models\\general_free_recall_model_Murdock_Roberts.lisp\")\n",
    "        #loaded = actr.load_act_r_model(r\"C:\\Users\\cleme\\Documents\\Education\\RUG\\First-Year_Research\\My_Project\\Model\\models\\csm_free_recall_model.lisp\")\n",
    "    elif subject == \"depressed\":\n",
    "        loaded = actr.load_act_r_model(r\"C:\\Users\\cleme\\Documents\\Education\\RUG\\First-Year_Research\\My_Project\\Model\\models\\rumination_free_recall_model_vanVugt.lisp\")\n",
    "    \n",
    "    #print(\"\\n\\n############################################# Inside setup_experiment\")\n",
    "    #print(f'\\nLoaded Act-r model = {loaded}\\n')  \n",
    "\n",
    "    window = actr.open_exp_window(\"Free Recall Experiment\", width=1024, height=768, visible=human) # 15inch resolution window\n",
    "    actr.install_device(window) \n",
    "    return window    \n",
    "\n",
    "# def record_associated_list(item):\n",
    "#     '''\n",
    "#     Register which list the recalled words belong to (to identify prior-list intruisions)\n",
    "#     '''\n",
    "#     associated_list = item\n",
    "\n",
    "def record_words_recalled(item1, item2):\n",
    "    '''\n",
    "    Register which words were recalled during the experiment for a specific wordlist and strip the numbers\n",
    "    '''\n",
    "    valence = ''.join(char for char in item1 if not char.isdigit())\n",
    "    item_idx = ''.join(char for char in item1 if char.isdigit())\n",
    "    context = str(item2)\n",
    "    \n",
    "    if str(item2) != 'RUMINATION' and str(item1) not in buffer_items:\n",
    "        recalled_words[current_list].append((valence, item_idx, context))\n",
    "    \n",
    "    #print(valence, item_idx, context)\n",
    "\n",
    "def record_words_rehearsed(item):\n",
    "    '''\n",
    "    Register amount of rehearsals per word for each wordlist\n",
    "    '''\n",
    "    rehearsed_words[current_list][item] += 1\n",
    "\n",
    "def create_lplot(idx, xlabel, ylabel, x, y, xticks_len, filename, ytick_range=None, show=False):\n",
    "    '''\n",
    "    Create line plot using matplotlib\n",
    "    '''\n",
    "    plt.figure(idx)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.plot(x, y)\n",
    "    plt.xticks(np.arange(0, xticks_len, 1)) \n",
    "    plt.yticks(ytick_range)\n",
    "    #plt.savefig(\"images/\"+subject+\"_\"+filename, bbox_inches='tight')\n",
    "    if show:\n",
    "        plt.show()    \n",
    "\n",
    "        \n",
    "def create_result_dict():\n",
    "    '''\n",
    "    Use a module-level function, instead of lambda function, to enable pickling it\n",
    "    '''\n",
    "    return defaultdict(int)\n",
    "\n",
    "## Creating different pickle files to store results from multiple hyper-parameter values.\n",
    "\n",
    "\n",
    "def analysis(wlist_amount, show_plots=False):\n",
    "    '''\n",
    "    Review results of the recall experiment\n",
    "    '''\n",
    "    global results\n",
    "    valence_counts = {'positive':0, 'negative':0, 'neutral':0}\n",
    "    result_dict = defaultdict(create_result_dict) # instead of defaultdict(lambda: defaultdict(int))\n",
    "    first_recall = defaultdict(int)\n",
    "    recall_probability = defaultdict(int)\n",
    "    rehearse_frequency = defaultdict(int)\n",
    "    pli_dict = defaultdict(int)\n",
    "    transitions_amnt = 0\n",
    "    thought_train_len = []\n",
    "    \n",
    "    \n",
    "    for key, val in recalled_words.items():\n",
    "        thought_train_len.extend([(k, sum(1 for _ in count)) for k, count in groupby([val[0] for val in val[2:]])])\n",
    "        for idx, (retrieved_word, item_num, _) in enumerate(val[2:]):\n",
    "            if idx != 0:\n",
    "                if retrieved_word != val[2:][idx-1][0]:\n",
    "                    transitions_amnt += 1/wlist_amount # average over word lists\n",
    "    print(f'Avg. Amount of recall transitions = {int(transitions_amnt)}')\n",
    "    \n",
    "    neg_thought_train_len = 0\n",
    "    neg_divider = 0.0001\n",
    "    for x in thought_train_len:\n",
    "        if x[0] == 'negative':\n",
    "            neg_divider += 1\n",
    "            neg_thought_train_len += x[1]\n",
    "    avg_neg_thought_train_len = round(neg_thought_train_len/neg_divider, 3)\n",
    "    print(f'Avg. Negative Thought train length = {avg_neg_thought_train_len}')            \n",
    "    \n",
    "    \n",
    "    for list_num, wlist in wlist_for_analysis.items():\n",
    "        if list_num < wlist_amount:\n",
    "            for key, val in recalled_words.items():\n",
    "                if key==list_num:\n",
    "#                     first_recall[wlist.index(''.join(val[0][0:2]))] += 1\n",
    "                    for idx, word in enumerate(wlist):\n",
    "#                         first_recall[idx] += 0\n",
    "                        if ((''.join(char for char in word if not char.isdigit()), \n",
    "                             ''.join(char for char in word if char.isdigit()), val[0][2])) in val:\n",
    "                            recall_probability[idx] += 1\n",
    "                        else:\n",
    "                            recall_probability[idx] += 0\n",
    "                for retrieved_word, item_num, list_idx in val[2:4]:\n",
    "                    result_dict[\"pstart\"][retrieved_word] += 1  \n",
    "                for retrieved_word, item_num, list_idx in val[4:-2]:\n",
    "                    result_dict[\"pstay\"][retrieved_word] += 1\n",
    "                for retrieved_word, item_num, list_idx in val[-2:]:\n",
    "                    result_dict[\"pstop\"][retrieved_word] += 1 \n",
    "            for key, val in rehearsed_words.items():\n",
    "                if key==list_num:\n",
    "                    for idx, word in enumerate(wlist):\n",
    "                        rehearse_frequency[idx] += rehearsed_words[key][word]\n",
    "    \n",
    "    \n",
    "#     for key, val in first_recall.items():\n",
    "#         first_recall[key] = val/wlist_amount\n",
    "\n",
    "    for key, val in recall_probability.items():\n",
    "        recall_probability[key] = val/wlist_amount\n",
    "\n",
    "    for key, val in rehearse_frequency.items():\n",
    "        rehearse_frequency[key] = val/wlist_amount      \n",
    "      \n",
    "    #count words per valence\n",
    "    for key, value in recalled_words.items():\n",
    "        for word in set(value):\n",
    "            if word[0] == 'negative':\n",
    "                valence_counts['negative'] += 1\n",
    "            elif word[0] == 'positive':\n",
    "                valence_counts['positive'] += 1\n",
    "            else:\n",
    "                valence_counts['neutral'] += 1\n",
    "    valence_counts['positive'] = valence_counts['positive'] / wlist_amount\n",
    "    valence_counts['negative'] = valence_counts['negative'] / wlist_amount\n",
    "    valence_counts['neutral'] = valence_counts['neutral'] / wlist_amount\n",
    "    \n",
    "    #Calculate prior-list intrustions\n",
    "    #subjects committed an average of 0.61 PLIs per list (Zaromb et al., 2006)\n",
    "    \n",
    "    if len(recalled_words) > 1:\n",
    "        overall_pli = 0\n",
    "        for key, value in recalled_words.items():\n",
    "            if key > 0:\n",
    "                intruding_list = []\n",
    "                pli = 0\n",
    "                for word_info in value:\n",
    "                    associated_list = int(re.findall(r'\\d+', word_info[2])[0]) #extract just the number from the context and turn into int\n",
    "                    if associated_list != key:\n",
    "                        intruding_list.append(associated_list)\n",
    "                        pli += 1\n",
    "\n",
    "                print(f'PLIs on list {key}: {pli}')\n",
    "                if intruding_list:\n",
    "                    print(f'The PLIs came from {intruding_list}')\n",
    "                overall_pli += pli\n",
    "                \n",
    "        \n",
    "            pli_dict[key] = overall_pli\n",
    "            \n",
    "        avg_pli = overall_pli/(len(recalled_words)-1)\n",
    "        print(f'Average number of PLIs: {avg_pli}') #minus 1 because no PLI possible on LIST0\n",
    "       \n",
    "    xticks_len = len(word_lists_dict[0])\n",
    "    \n",
    "    #results['x']['data'].append(range(len(word_lists_dict[0])))\n",
    "    #results['xticks_len']['data'].append(len(word_lists_dict[0]) )\n",
    "    results['rehearse_frequency']['data'] = list(rehearse_frequency.values())\n",
    "    results['recall_probability']['data'] = list(recall_probability.values())\n",
    "#     results['first_recall']['data'] = list(first_recall.values())\n",
    "    results['pli']['data'] = list(pli_dict.values())\n",
    "    \n",
    "    with open(filename, 'w') as outfile:\n",
    "        json.dump(results, outfile)\n",
    "        \n",
    "#     create_lplot(0, 'Serial input position', 'Rehearse Frequency', range(len(word_lists_dict[0])), list(rehearse_frequency.values()), \n",
    "#                 xticks_len, f'rehearse_frequency_{list_length}_{list_amount}_{rehearsal_time}_{recall_time}_{delay}.png', None, show_plots)\n",
    "\n",
    "#     create_lplot(1, 'Serial input position', 'Starting Recall', range(len(word_lists_dict[0])), list(first_recall.values()), \n",
    "#                 xticks_len, f'starting_recall_{list_length}_{list_amount}_{rehearsal_time}_{recall_time}_{delay}.png', np.arange(0, .5, .1), show_plots)                \n",
    "\n",
    "#     create_lplot(2, 'Serial input position', 'Recall Probability', range(len(word_lists_dict[0])), list(recall_probability.values()), \n",
    "#                 xticks_len, f'recall_probability_{list_length}_{list_amount}_{rehearsal_time}_{recall_time}_{delay}.png', np.arange(0, 1, .1), show_plots)   \n",
    "    \n",
    "#     create_lplot(3, 'Serial input position', 'Accuracy', range(len(word_lists_dict[0])), list(recall_accuracy.values()), \n",
    "#                 xticks_len, 'recall_accuracy.png', np.arange(0, 1, .1), show_plots) \n",
    "\n",
    "    file = open(\"results_\"+subject+\".pickle\",\"wb\")\n",
    "    pickle.dump(result_dict, file)\n",
    "    file.close()\n",
    "\n",
    "    return result_dict, avg_neg_thought_train_len, transitions_amnt, valence_counts\n",
    "\n",
    "def do_experiment(subj=\"controls\", human=False, wlist_amount=2000, distractor_time=0, rumination_chunks=0, neg_bias=0):\n",
    "    '''\n",
    "    Run the experiment\n",
    "    '''\n",
    "    check_and_create_lists()\n",
    "    global word_lists_dict, subject\n",
    "    \n",
    "    subject = subj\n",
    "    \n",
    "    assert wlist_amount <= len(word_lists_dict), \"Chosen too many lists, choose less or create more word lists using function: create_lists()\"\n",
    "    \n",
    "#     print(\"###################################################\\n\")\n",
    "#     print(\"The original word list \\n\")\n",
    "#     print(display_word_lists())\n",
    "    \n",
    "#     print(\"\\n###################################################\\n\")\n",
    "#     print(\"Experiment started, Trying to understand the flow\\n\")\n",
    "    \n",
    "    #buffers_to_clear = ['goal', \"imaginal\", \"retrieval\", \"production\"]\n",
    "    \n",
    "    \n",
    "    actr.reset()\n",
    "    \n",
    "    window = setup_experiment(human)\n",
    "    \n",
    "    setup_dm(word_lists_dict, condition = subject, rumination_chunks=rumination_chunks, neg_bias=neg_bias)\n",
    "\n",
    "    for idx, (key, value) in enumerate(word_lists_dict.items()):\n",
    "        \n",
    "        #window = setup_experiment(human)\n",
    "\n",
    "        global current_list\n",
    "        current_list = idx # keep track for which list words are recalled\n",
    "\n",
    "        #setup_dm(key, value)\n",
    "                \n",
    "        prepare_for_memorization()\n",
    "        \n",
    "        actr.mod_focus('context', 'list'+str(current_list))\n",
    "        \n",
    "        #actr.run(2, human)\n",
    "        \n",
    "        #actr.load_act_r_code('~;Users;cleme;Documents;Education;RUG;First-Year_Research;My_Project;Model;modelsset_all_base_levels.lisp')\n",
    "    \n",
    "        actr.add_command(\"retrieved-word\", record_words_recalled,\"Retrieves recalled words.\")\n",
    "        actr.add_command(\"rehearsed-word\", record_words_rehearsed,\"Retrieves rehearsed words.\")\n",
    "        \n",
    "    \n",
    "#         print(\"\\n##################  Model started rehearsal \")\n",
    "        for idx, word in enumerate(value):\n",
    "            actr.mod_focus('context', 'list'+str(current_list))\n",
    "            if \"neutral\" in word:\n",
    "                color = \"black\"\n",
    "            elif \"positive\" in word:\n",
    "                color = \"green\"\n",
    "            else:\n",
    "                color = \"red\"\n",
    "            actr.add_text_to_exp_window(window, word, x=475-len(word) , y=374, color=color, font_size=20) # change later \n",
    "            #print(idx, word, f'list{key}')\n",
    "            \n",
    "            actr.run(rehearsal_time, human) # True when choosing Human, False when choosing differently\n",
    "            \n",
    "            #actr.whynot_dm()\n",
    "            #actr.print_dm_finsts()\n",
    "            #print(actr.buffer_chunk('goal'))\n",
    "#             actr.buffer_status('retrieval')\n",
    "#             actr.buffer_status('imaginal')\n",
    "            \n",
    "            actr.clear_exp_window(window)\n",
    "            actr.run(0.5, human)  # 500-ms blank screen \n",
    "        \n",
    "        if distractor_time:\n",
    "            prepare_for_distractor()\n",
    "            actr.mod_focus('state', 'begin-task')\n",
    "            actr.run(distractor_time, human)\n",
    "            \n",
    "        \n",
    "        prepare_for_recall(distractor_time)\n",
    "        \n",
    "        actr.goal_focus('startrecall')\n",
    "        actr.mod_focus('context', 'list'+str(current_list))\n",
    "\n",
    "        #actr.goal_focus('startrecall')\n",
    "       \n",
    "        #for buff in [\"imaginal\", \"retrieval\", \"production\"]:\n",
    "        #    actr.clear_buffer(buff)\n",
    "        \n",
    "        \n",
    "        #actr.remove_command(\"rehearsed-word\")\n",
    "        \n",
    "#         print(\"\\n##################  Model finished rehearsal, list of rehearsed words is \")\n",
    "#         print(f'{rehearsed_words}\\n')\n",
    "#         print(\"\\n##################  Model started recall \")\n",
    "        #actr.goal_focus(\"startrecall\") # set goal to start recalling\n",
    "    \n",
    "        actr.run(recall_time, human)  \n",
    "        \n",
    "#         for buffer in buffers_to_clear:\n",
    "#             actr.clear_buffer(buffer)\n",
    "    \n",
    "        #actr.remove_command(\"retrieved-word\")\n",
    "        \n",
    "#         print(\"\\n##################  Model finished recall, list of recalled words is \")\n",
    "#         print(f'{recalled_words}\\n')\n",
    "        print(f'Experiment {idx+1}/{wlist_amount} completed!', end=\"\\r\")\n",
    "        if idx == wlist_amount-1: # run for a chosen amount of word lists\n",
    "            break\n",
    "    close_exp_window() # close window at end of experiment\n",
    "    \n",
    "    num_recalled, num_recalled_unique = 0, 0\n",
    "    for key, val in recalled_words.items():\n",
    "        correct_recalls = []\n",
    "        print(key, current_list)\n",
    "        print(val)\n",
    "        for word in val:\n",
    "            if word[2] == f'LIST{key}':\n",
    "                correct_recalls.append(word[0:2])\n",
    "                num_recalled += 1\n",
    "        num_recalled_unique += len(set(correct_recalls))\n",
    "        print(f'\\n\\nList {key} (length={len(correct_recalls)}, unique={len(set(correct_recalls))})\\n')\n",
    "        \n",
    "    avg_recalled = num_recalled//wlist_amount\n",
    "    avg_unique_recalled = num_recalled_unique//wlist_amount\n",
    "    \n",
    "    print(f'Avg. Number of words recalled = {avg_recalled}')\n",
    "    print(f'Avg. Number of unique words recalled = {avg_unique_recalled}')\n",
    "    \n",
    "    #analysis(list_amount, False)\n",
    "    results, avg_neg_train, num_transitions, valence_counts = analysis(list_amount, False)        \n",
    "\n",
    "    for key, val in results.items():\n",
    "        print(f'{key} = {dict(val)}')\n",
    "    print()\n",
    " \n",
    "\n",
    "    print(\"\\n\\n#############################################\")\n",
    "    print(f'\\n[{subject}] Results!\\n')\n",
    "    return avg_recalled, avg_unique_recalled, avg_neg_train, num_transitions, valence_counts, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_agents = 10 #set number of agents per condition\n",
    "\n",
    "list_length = 22 #includes 4 buffer words\n",
    "rehearsal_time = 6\n",
    "num_lists = 3 #number of lists per agent\n",
    "distractor_time = 0\n",
    "\n",
    "#for rumination model\n",
    "rumination_chunks = 15\n",
    "neg_bias = 2.5 #only relevant if rumination_chunks > 0\n",
    "#subject = 'controls' # 'controls', 'depressed'\n",
    "\n",
    "#experimental conditions [rehearsal time, list length] -  van Vugt 2012 [6,20]\n",
    "#experimental_setup = [[6,22]] #18 plus 4 buffer items automatically added\n",
    "\n",
    "#to save files to different directory for different numbers of agents\n",
    "output_path = f'./results/agents_{num_agents}_vV_mixed/'\n",
    "if not os.path.isdir(output_path):\n",
    "    os.mkdir(f'results/agents_{num_agents}_vV_mixed')\n",
    "path = output_path\n",
    "\n",
    "\n",
    "valences = ['neutral', 'positive', 'negative']\n",
    "results_per_condition = {'controls': None, 'depressed': None}\n",
    "pstats_per_condition = {'controls': None, 'depressed': None}\n",
    "valences_per_condition = {'controls': {'positive':0, 'negative':0, 'neutral':0},\n",
    "                          'depressed': {'positive':0, 'negative':0, 'neutral':0}}\n",
    "\n",
    "for condition in ['controls', 'depressed']:\n",
    "#     for parameter in experimental_setup:\n",
    "#         rh = parameter[0]\n",
    "#         ll = parameter[1]\n",
    "    \n",
    "    positives = 0\n",
    "    negatives = 0\n",
    "    neutrals = 0\n",
    "    \n",
    "    results_dict = {}\n",
    "    pstats = {}\n",
    "    \n",
    "    total_recalled = 0\n",
    "    total_unique = 0\n",
    "\n",
    "    neg_train_list = []\n",
    "    transitions_list = []\n",
    "\n",
    "    pstats = {'pstart': {'neutral':0, 'positive':0, 'negative':0},\n",
    "                'pstop': {'neutral':0, 'positive':0, 'negative':0},\n",
    "                'pstay': {'neutral':0, 'positive':0, 'negative':0}}\n",
    "\n",
    "    print(\"-------------------------------------------------------------------\")\n",
    "    print(\"Experimental condition:\")\n",
    "    print(f\"Number of lists: {num_lists}\")\n",
    "    print(f\"Words per list: {list_length}\")\n",
    "    print(f\"Rehearsal time: {rehearsal_time} seconds\")\n",
    "\n",
    "    for agent in range(num_agents):\n",
    "\n",
    "        print(\"-------------------------------------------------------------------\")\n",
    "        print(f\"Started for agent_{agent}\")\n",
    "        print(f\"Words per list: {list_length}, rehearsal time: {rehearsal_time} sec\")\n",
    "        __init__(agent, rehearsal_time=rehearsal_time, list_length=list_length, list_amount=num_lists, path=path,\n",
    "                rum_chunks = rumination_chunks)\n",
    "\n",
    "        try:\n",
    "            num_recalled, num_unique, avg_neg_train, num_transitions, valence_counts, results = do_experiment(condition,False,\n",
    "                                                                                              list_amount,\n",
    "                                                                                            distractor_time=distractor_time,\n",
    "                                                                                            rumination_chunks=rumination_chunks,\n",
    "                                                                                             neg_bias=neg_bias)\n",
    "            total_recalled += num_recalled\n",
    "            total_unique += num_unique\n",
    "\n",
    "            neg_train_list.append(avg_neg_train)\n",
    "            transitions_list.append(num_transitions)\n",
    "\n",
    "            positives += valence_counts['positive']\n",
    "            negatives += valence_counts['negative']\n",
    "            neutrals += valence_counts['neutral']\n",
    "\n",
    "            for valence in valences:\n",
    "                pstats['pstart'][valence] += results['pstart'][valence]\n",
    "                pstats['pstay'][valence] += results['pstay'][valence]\n",
    "                pstats['pstop'][valence] += results['pstop'][valence]\n",
    "\n",
    "        except ZeroDivisionError:\n",
    "            print(\"\\nAgent recalled 0 items.\")\n",
    "\n",
    "    avg_recall = total_recalled / num_agents\n",
    "    avg_unique = total_unique / num_agents\n",
    "\n",
    "    avg_neg_train_len = sum(neg_train_list) / num_agents\n",
    "    avg_transitions = sum(transitions_list) / num_agents\n",
    "\n",
    "    avg_positives = positives / num_agents\n",
    "    avg_negatives = negatives / num_agents\n",
    "    avg_neutrals = neutrals / num_agents\n",
    "    \n",
    "    print(positives)\n",
    "    print(avg_positives)\n",
    "\n",
    "    results_dict[f'{condition}'] = [avg_recall, avg_unique, avg_neg_train_len, avg_transitions]\n",
    "\n",
    "    print(f\"Experimental Condition\\nWords per list: {list_length}, rehearsal time: {rehearsal_time} sec\")\n",
    "    print(f\"\\nAverage number of recalled words ({num_agents} agents): {avg_recall}\")\n",
    "    print(f\"Unique: {avg_unique}\")\n",
    "    \n",
    "    results_per_condition[condition] = results_dict\n",
    "    pstats_per_condition[condition] = pstats\n",
    "    valences_per_condition[condition]['positive'] = round(avg_positives, 2)\n",
    "    valences_per_condition[condition]['negative'] = round(avg_negatives, 2)\n",
    "    valences_per_condition[condition]['neutral'] = round(avg_neutrals, 2)\n",
    "    \n",
    "    print(results_per_condition, pstats_per_condition, valences_per_condition)\n",
    "    \n",
    "    for key, value in results_dict.items():\n",
    "        print(f'\\n{condition}')\n",
    "        print(f'\\n{key}')\n",
    "        print(f'\\nAverage number of recalled words: {value[0]}')\n",
    "        print(f'\\nAverage number of unique words: {value[1]}')\n",
    "        print(f'\\nAverage length of negative thought trains: {value[2]}')\n",
    "        print(f'\\nAverage number of recall transitions: {value[3]}')\n",
    "        print('-------------------------------------------------------------\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "max_list_length = 40\n",
    "f, ax = plt.subplots(1) #set up plot\n",
    "\n",
    "#path = f'murdock/agents_{num_agents}_controls_vV/'\n",
    "#path = f'murdock/agents_{num_agents}/'\n",
    "\n",
    "f.set_size_inches(20, 10.5)\n",
    "\n",
    "for condition in ['controls', 'depressed']:\n",
    "    if condition == 'controls':\n",
    "        color = 'navy'\n",
    "    else:\n",
    "        color = 'red'\n",
    "    \n",
    "    for key, value in results_per_condition[condition].items():\n",
    "        print('--------------------------------------------------------------\\n')\n",
    "        print(f'\\n{key}')\n",
    "        print(f'\\nAverage number of recalled words: {value[0]}')\n",
    "        print(f'\\nAverage number of unique words: {value[1]}')\n",
    "        print(f'\\nAverage length of negative thought trains: {round(value[2],2)}')\n",
    "        print(f'\\nAverage number of recall transitions: {round(value[3],2)}')\n",
    "#         print('-------------------------------------------------------------\\n')\n",
    "    \n",
    "    print('\\nAverage word counts per valence:')\n",
    "    print(valences_per_condition[condition])\n",
    "    \n",
    "    for stat, counts in pstats_per_condition[condition].items():\n",
    "        print(f'\\n{stat}')\n",
    "        total = sum(counts.values())\n",
    "        for valence, count in counts.items():\n",
    "            pstats_per_condition[condition][stat][valence] = round(count/total,2)\n",
    "            print(f'{valence}: {round(count/total,2)}')\n",
    "\n",
    "#     for parameter in experimental_setup:\n",
    "#         rh = parameter[0] #rehearsal time\n",
    "#         ll = parameter[1] #words per list\n",
    "\n",
    "    files = [] #Storing all the relevant files to work on them later\n",
    "    pattern = f\"words_{list_length}_lists_{num_lists}_{condition}_rh_time_{rehearsal_time}*.txt\" # Pattern for matching the filename for data retrieval\n",
    "    for file in os.listdir(path): #Lists all the files and directories within the folder\n",
    "        if fnmatch.fnmatch(file, pattern): #matches the above declared patter with the filenames from listdir()\n",
    "            files.append(file) #Appends the file to make it available for later use.\n",
    "\n",
    "    # Initializing all the parameters needed for the plots\n",
    "    idx = [0,1,2]\n",
    "    xlabel = 'Serial Input Position'\n",
    "    ylabel = ['Rehearse Frequency','Starting Probability','Recall Probability']\n",
    "    xticks_len = max_list_length+10\n",
    "    rehearse_frequency = []\n",
    "    recall_probability = []\n",
    "    first_recall = []\n",
    "    pli_list = []\n",
    "    neg_thought_train = []\n",
    "    transitions = []\n",
    "\n",
    "    for file in files: #load the result files\n",
    "        with open(f\"{path}/{file}\") as f:\n",
    "            recall_stats = json.load(f)\n",
    "            if recall_stats['recall_probability']['data']:\n",
    "                recall_probability.append(recall_stats['recall_probability']['data'])\n",
    "            else: #if an agent failed to recall anything...\n",
    "                recall_probability.append([0]*ll)\n",
    "            if recall_stats['pli']['data']:\n",
    "                pli_list.append(recall_stats['pli']['data'])\n",
    "            else:\n",
    "                pli_list.append([0]*list_length)\n",
    "#             if results['neg_thought_train']['data']:\n",
    "#                 neg_thought_train.append(results['neg_thought_train']['data'])\n",
    "#             else:\n",
    "#                 neg_thought_train.append([0]*ll)\n",
    "#             if results['transitions']['data']:\n",
    "#                 transitions.append(results['transitions']['data'])\n",
    "#             else:\n",
    "#                 transitions.append([0]*ll)\n",
    "\n",
    "    #calculating avg stats per input position across agents            \n",
    "    avg_recall_probs = [sum(x)/num_agents for x in zip(*recall_probability)]\n",
    "    avg_pli = [sum(x)/num_agents for x in zip(*pli_list)]\n",
    "\n",
    "#     avg_neg_train = [sum(x)/num_agents for x in zip(*neg_thought_train)]\n",
    "#     avg_transitions = [sum(x)/num_agents for x in zip(*transitions)]\n",
    "\n",
    "    #print(f'{ll}-{rh}\\nP(First_Item): {round(avg_recall_probs[0],2)}\\nP(Final_Item): {round(avg_recall_probs[-1],2)}\\nAvg PLI: {sum(avg_pli)/(num_lists-1)}')\n",
    "    #print(f'\\nAverage negative thought train length: {round(sum(avg_neg_train)/(num_lists),2)}\\nAvg num transitions: {round(sum(avg_transitions)/(num_lists),2)}')\n",
    "\n",
    "    #plot results\n",
    "    x = range(list_length)\n",
    "    ax.plot(x[0:18], avg_recall_probs, marker = \"o\", label = f\"{condition}\", color = color)\n",
    "    #ax.set_xlim([0,ll])\n",
    "    plt.xticks(np.arange(0, 18, step=1), fontsize = 18)\n",
    "    plt.yticks(fontsize = 18)# Set label locations\n",
    "    ax.set_ylim([0,1])\n",
    "    ax.set_ylabel('Recall probability', fontsize = 20)\n",
    "    ax.set_xlabel('Serial input position', fontsize = 20)\n",
    "\n",
    "ax.legend()\n",
    "    #ax.legend(title='Condition', bbox_to_anchor=(1.05, 1), loc='upper left') #fontsize='xx-small')\n",
    "\n",
    "    #(\"murdock/images/\"+subject+\"_\"+filename, bbox_inches='tight')\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(3,2)\n",
    "f.set_size_inches(25, 30)\n",
    "conditions = ['controls', 'depressed']\n",
    "measures = ['Pstart', 'Pstay', 'Pstop']\n",
    "\n",
    "pstart_pos = []\n",
    "pstart_neg = []\n",
    "\n",
    "pstay_pos = []\n",
    "pstay_neg = []\n",
    "\n",
    "pstop_pos = []\n",
    "pstop_neg = []\n",
    "\n",
    "for condition in conditions:\n",
    "    \n",
    "    pstart_pos.append(pstats_per_condition[condition]['pstart']['positive'])\n",
    "    pstart_neg.append(pstats_per_condition[condition]['pstart']['negative'])\n",
    "\n",
    "    pstay_pos.append(pstats_per_condition[condition]['pstay']['positive'])\n",
    "    pstay_neg.append(pstats_per_condition[condition]['pstay']['negative'])\n",
    "\n",
    "    pstop_pos.append(pstats_per_condition[condition]['pstop']['positive'])\n",
    "    pstop_neg.append(pstats_per_condition[condition]['pstop']['negative'])\n",
    "\n",
    "\n",
    "pstart_dict = {'positive': pstart_pos, 'negative': pstart_neg}\n",
    "pstay_dict = {'positive': pstay_pos, 'negative': pstay_neg}\n",
    "pstop_dict = {'positive': pstop_pos, 'negative': pstop_neg}\n",
    "\n",
    "stats_dict = {'Pstart': pstart_dict, 'Pstay': pstay_dict, 'Pstop': pstop_dict}\n",
    "\n",
    "print(stats_dict)\n",
    "\n",
    "j = 0\n",
    "for key, val in stats_dict.items():\n",
    "    i = 0\n",
    "    \n",
    "    print(key)\n",
    "    print(j,i)\n",
    "   # for valence, result in val.items():\n",
    "\n",
    "    axs[j,i].set_ylim([0,0.8])\n",
    "    axs[j,i].set_facecolor('#d2fad4')\n",
    "    barlist1 = axs[j,i].bar(conditions, val['positive'])\n",
    "    barlist1[0].set_color('navy')\n",
    "    barlist1[1].set_color('r')\n",
    "    axs[j,i].set_ylabel(f'{key} (Positive)', fontsize = 18)\n",
    "    axs[j,i].tick_params(axis='y', labelsize = 18)\n",
    "    axs[j,i].tick_params(axis='x', labelsize=18)\n",
    "\n",
    "    i += 1\n",
    "    \n",
    "    print(j,i)\n",
    "\n",
    "    axs[j,i].set_ylim([0,0.8])\n",
    "    axs[j,i].set_facecolor('#fad9d9')\n",
    "    barlist2 = axs[j,i].bar(conditions, val['negative'])\n",
    "    barlist2[0].set_color('navy')\n",
    "    barlist2[1].set_color('r')\n",
    "    axs[j,i].set_ylabel(f'{key} (Negative)', fontsize = 18)\n",
    "    axs[j,i].tick_params(axis='y', labelsize = 18)\n",
    "    axs[j,i].tick_params(axis='x', labelsize=18)\n",
    "\n",
    "    j += 1\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in valences_per_condition.items():\n",
    "    print(key)\n",
    "    for k, v in val.items():\n",
    "        print(k)\n",
    "        print(round(v/6,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valences_per_condition[condition]\n",
    "\n",
    "f, axs = plt.subplots(1,3)\n",
    "f.set_size_inches(25, 8)\n",
    "\n",
    "\n",
    "axs[0].set_ylim([0,0.75])\n",
    "axs[0].set_facecolor('#d2fad4')\n",
    "barlist = axs[0].bar(conditions, [valences_per_condition['controls']['positive']/6,\n",
    "                     valences_per_condition['depressed']['positive']/6])\n",
    "\n",
    "barlist[0].set_color('navy')\n",
    "barlist[1].set_color('r')\n",
    "axs[0].set_ylabel(f'Mean percentage of recalled positive words', fontsize = 15)\n",
    "axs[0].tick_params(axis='y', labelsize = 18)\n",
    "axs[0].tick_params(axis='x', labelsize=18)\n",
    "\n",
    "\n",
    "axs[1].set_ylim([0,0.75])\n",
    "axs[1].set_facecolor('#fad9d9')\n",
    "barlist = axs[1].bar(conditions, [valences_per_condition['controls']['negative']/6,\n",
    "                     valences_per_condition['depressed']['negative']/6])\n",
    "barlist[0].set_color('navy')\n",
    "barlist[1].set_color('r')\n",
    "axs[1].set_ylabel(f'Mean percentage of recalled negative words', fontsize = 15)\n",
    "axs[1].tick_params(axis='y', labelsize = 18)\n",
    "axs[1].tick_params(axis='x', labelsize=18)\n",
    "\n",
    "\n",
    "axs[2].set_ylim([0,0.75])\n",
    "axs[2].set_facecolor('#f5f5f5')\n",
    "barlist = axs[2].bar(conditions, [valences_per_condition['controls']['neutral']/6,\n",
    "                     valences_per_condition['depressed']['neutral']/6])\n",
    "barlist[0].set_color('navy')\n",
    "barlist[1].set_color('r')\n",
    "axs[2].set_ylabel(f'Mean percentage of recalled neutral words', fontsize = 15)\n",
    "axs[2].tick_params(axis='y', labelsize = 18)\n",
    "axs[2].tick_params(axis='x', labelsize=18)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### do_experiment flow:\n",
    "\n",
    "1. check_and_create_lists\n",
    "\ta. create_lists\n",
    "\t   return word_lists_dict\n",
    "\t\ti. add_words\n",
    "            adds to word_lists_dict\n",
    "\n",
    "2. setup_experiment\n",
    "    returns window\n",
    "      model is loaded\n",
    "\n",
    "\n",
    "3. setup_dm\n",
    "\n",
    "\n",
    "4. prepare_for_recall\n",
    "\n",
    "\n",
    "5. close_exp_window\n",
    "\n",
    "\n",
    "6. analysis\n",
    "    return result_dict\n",
    "        contains pstart, pstay, pstop\n",
    "    prints Avg recall transitions\n",
    "    \n",
    "    prints Avg negative thought train length\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = []\n",
    "with(open(r\"word_lists\\word_lists_dict_18_3.pickle\", \"rb\")) as openfile:\n",
    "    while True:\n",
    "        try:\n",
    "            objects.append(pickle.load(openfile))\n",
    "        except EOFError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for idx, (key, val) in enumerate(word_lists_dict.items()):\n",
    "#    print(idx, (key, val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = open(f\"word_lists/word_lists_dict_22_3.pickle\",\"rb\")\n",
    "# #file = open(f\"word_lists_dict_100_items_only.pickle\",\"rb\")\n",
    "# word_lists_dict = pickle.load(file)  \n",
    "# file.close()\n",
    "\n",
    "# word_lists_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#actr.reset()\n",
    "#setup_dm(word_lists_dict)\n",
    "#actr.sdp(':creation-time', -1000, ':reference-list', list(np.linspace(0, -1000, 50)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_lists_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recalled_words.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     for key, val in recalled_words.items():\n",
    "#         print(key, current_list)\n",
    "#         print(val)\n",
    "#         for word in val:\n",
    "#             print(word[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#actr.load_act_r_model(r\"C:\\Users\\cleme\\Documents\\Education\\RUG\\First-Year_Research\\My_Project\\Model\\models\\rumination_free_recall_model_v1.lisp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_per_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recalled_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pstats_per_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valences_per_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for condition, counts in valences_per_condition.items():\n",
    "    print(condition)\n",
    "    print(counts)\n",
    "    for valence in valences:\n",
    "        print(counts[valence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valences_per_condition['depressed']['positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
