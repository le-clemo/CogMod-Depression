{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACT-R connection has been started.\n"
     ]
    }
   ],
   "source": [
    "import actr\n",
    "import pickle\n",
    "import random\n",
    "import os\n",
    "import fnmatch\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from itertools import groupby\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observed Issues:\n",
    "(see file \"current_issues\")\n",
    "\n",
    "- Recency effect still too weak.\n",
    "\n",
    "- Primacy effect too strong.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of words in each list i.e. list_length should be n where (n-2)%3 == 0 because 2 neutral words are added in each list.\n",
    "\n",
    "#### The adjustable parameters in this experiment code.\n",
    "    - number of agents (top of next cell)\n",
    "    - experimental conditions (further below) --> multiple conditions can be set in a list of lists [[rehearsal time1, num words per list 1], [rehearsal time 2, num words per list 2], ...]\n",
    "    - Number of lists (further below)\n",
    "#### Adjustable parameters in ACT-R\n",
    "    - :declarative-num-finsts 21 ; number of items that are kept as recently retrieved (Change it to 5) \n",
    "    - :declarative-finst-span 21 ; how long items stay in the recently-retrieved state (5,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module actr:\n",
      "\n",
      "NAME\n",
      "    actr\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        actr\n",
      "        interface\n",
      "        request\n",
      "    \n",
      "    class actr(builtins.object)\n",
      "     |  actr(host, port)\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, host, port)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  add_command(self, name, function, documentation='No documentation provided.', single=True, actr_name=None)\n",
      "     |  \n",
      "     |  evaluate(self, *params)\n",
      "     |  \n",
      "     |  evaluate_single(self, *params)\n",
      "     |  \n",
      "     |  monitor_command(self, original, monitor)\n",
      "     |  \n",
      "     |  remove_command(self, name)\n",
      "     |  \n",
      "     |  remove_command_monitor(self, original, monitor)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class interface(builtins.object)\n",
      "     |  interface(host, port)\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, host, port)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  add_command(self, name, function)\n",
      "     |  \n",
      "     |  collect_data(self)\n",
      "     |  \n",
      "     |  echo_output(self)\n",
      "     |  \n",
      "     |  no_output(self)\n",
      "     |  \n",
      "     |  output_monitor(self, string)\n",
      "     |  \n",
      "     |  process_message(self, d)\n",
      "     |  \n",
      "     |  run_command(self, command, command_name, model, id, params)\n",
      "     |  \n",
      "     |  send(self, method, *params)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class request(builtins.object)\n",
      "     |  request(id)\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, id)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  notify_result(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "FUNCTIONS\n",
      "    act_r_output(output)\n",
      "    \n",
      "    add_button_to_exp_window(window, text='', x=0, y=0, action=None, height=20, width=75, color='gray')\n",
      "    \n",
      "    add_command(name, function=None, documentation='No documentation provided.', single=True, local_name=None)\n",
      "    \n",
      "    add_dm(*chunks)\n",
      "    \n",
      "    add_dm_fct(chunks)\n",
      "    \n",
      "    add_image_to_exp_window(window, text, file, x=0, y=0, width=50, height=50, action=None)\n",
      "    \n",
      "    add_items_to_exp_window(window, *items)\n",
      "    \n",
      "    add_line_to_exp_window(window, start, end, color=False)\n",
      "    \n",
      "    add_text_to_exp_window(window, text, x=0, y=0, color='black', height=20, width=75, font_size=12)\n",
      "    \n",
      "    add_visicon_features(*features)\n",
      "    \n",
      "    all_productions()\n",
      "    \n",
      "    buffer_chunk(*params)\n",
      "    \n",
      "    buffer_read(buffer)\n",
      "    \n",
      "    buffer_status(*params)\n",
      "    \n",
      "    buffers()\n",
      "    \n",
      "    chunk_copied_from(chunk_name)\n",
      "    \n",
      "    chunk_p(chunk_name)\n",
      "    \n",
      "    chunk_slot_value(chunk_name, slot_name)\n",
      "    \n",
      "    chunk_spec_to_chunk_def(spec_id)\n",
      "    \n",
      "    clear_buffer(buffer)\n",
      "    \n",
      "    clear_exp_window(win=None)\n",
      "    \n",
      "    command_output(string)\n",
      "    \n",
      "    connection()\n",
      "    \n",
      "    copy_chunk(chunk_name)\n",
      "    \n",
      "    correlation(results, data, output=True)\n",
      "    \n",
      "    create_image_for_exp_window(window, text, file, x=0, y=0, width=50, height=50, action=None)\n",
      "    \n",
      "    current_model()\n",
      "    \n",
      "    define_chunk_spec(*spec)\n",
      "    \n",
      "    define_chunks(*chunks)\n",
      "    \n",
      "    define_chunks_fct(chunks)\n",
      "    \n",
      "    define_module(name, buffers, params, interface=None)\n",
      "    \n",
      "    delete_all_visicon_features()\n",
      "    \n",
      "    delete_chunk(name)\n",
      "    \n",
      "    delete_visicon_features(*features)\n",
      "    \n",
      "    dm(*params)\n",
      "    \n",
      "    extend_possible_slots(slot_name, warn=True)\n",
      "    \n",
      "    get_history_data(history, *params)\n",
      "    \n",
      "    get_parameter_value(param)\n",
      "    \n",
      "    get_system_parameter_value(param)\n",
      "    \n",
      "    get_time(model_time=True)\n",
      "    \n",
      "    goal_focus(goal=None)\n",
      "    \n",
      "    hide_output()\n",
      "    \n",
      "    history_data_available(history, file=False, *params)\n",
      "    \n",
      "    install_device(device)\n",
      "    \n",
      "    load_act_r_code(path)\n",
      "    \n",
      "    load_act_r_model(path)\n",
      "    \n",
      "    mean_deviation(results, data, output=True)\n",
      "    \n",
      "    mod_chunk(chunk_name, *mods)\n",
      "    \n",
      "    mod_focus(*mods)\n",
      "    \n",
      "    model_output(output_string)\n",
      "    \n",
      "    modify_line_for_exp_window(line, start, end, color=False)\n",
      "    \n",
      "    modify_visicon_features(*features)\n",
      "    \n",
      "    modules_parameters(module)\n",
      "    \n",
      "    modules_with_parameters()\n",
      "    \n",
      "    monitor_command(original, monitor)\n",
      "    \n",
      "    mp_models()\n",
      "    \n",
      "    mp_show_queue(indicate_traced=False)\n",
      "    \n",
      "    mp_time()\n",
      "    \n",
      "    mp_time_ms()\n",
      "    \n",
      "    new_digit_sound(digit, onset=False, time_in_ms=False)\n",
      "    \n",
      "    new_tone_sound(freq, duration, onset=False, time_in_ms=False)\n",
      "    \n",
      "    new_word_sound(word, onset=False, location='external', time_in_ms=False)\n",
      "    \n",
      "    open_exp_window(title, visible=True, width=300, height=300, x=300, y=300)\n",
      "    \n",
      "    pbreak(*params)\n",
      "    \n",
      "    pdisable(*params)\n",
      "    \n",
      "    penable(*params)\n",
      "    \n",
      "    permute_list(l)\n",
      "    \n",
      "    pp(*params)\n",
      "    \n",
      "    pprint_chunks(*chunks)\n",
      "    \n",
      "    predict_bold_response(start=None, end=None, output=None)\n",
      "    \n",
      "    print_activation_trace(time, ms=True)\n",
      "    \n",
      "    print_audicon()\n",
      "    \n",
      "    print_chunk_activation_trace(chunk, time, ms=True)\n",
      "    \n",
      "    print_dm_finsts()\n",
      "    \n",
      "    print_visicon()\n",
      "    \n",
      "    print_warning(warning)\n",
      "    \n",
      "    printed_audicon()\n",
      "    \n",
      "    printed_parameter_details(param)\n",
      "    \n",
      "    printed_visicon()\n",
      "    \n",
      "    process_events()\n",
      "    \n",
      "    process_history_data(processor, file=False, data_params=None, processor_params=None)\n",
      "    \n",
      "    punbreak(*params)\n",
      "    \n",
      "    purge_chunk(name)\n",
      "    \n",
      "    random(value)\n",
      "    \n",
      "    record_history(*params)\n",
      "    \n",
      "    release_chunk_spec(spec_id)\n",
      "    \n",
      "    reload(compile=False)\n",
      "    \n",
      "    remove_command(name)\n",
      "    \n",
      "    remove_command_monitor(original, monitor)\n",
      "    \n",
      "    remove_items_from_exp_window(window, *items)\n",
      "    \n",
      "    reset()\n",
      "    \n",
      "    resume_output()\n",
      "    \n",
      "    run(time, real_time=False)\n",
      "    \n",
      "    run_full_time(time, real_time=False)\n",
      "    \n",
      "    run_n_events(event_count, real_time=False)\n",
      "    \n",
      "    run_until_condition(condition, real_time=False)\n",
      "    \n",
      "    run_until_time(time, real_time=False)\n",
      "    \n",
      "    running()\n",
      "    \n",
      "    save_history_data(history, file, comment='', *params)\n",
      "    \n",
      "    saved_activation_history()\n",
      "    \n",
      "    schedule_break_relative(time_delay, time_in_ms=False, priority=':max', details=None)\n",
      "    \n",
      "    schedule_event(time, action, params=None, module=':NONE', priority=0, maintenance=False, destination=None, details=None, output=True, time_in_ms=False, precondition=None)\n",
      "    \n",
      "    schedule_event_after_module(after_module, action, params=None, module=':NONE', maintenance=False, destination=None, details=None, output=True, precondition=None, dynamic=False, delay=True, include_maintenance=False)\n",
      "    \n",
      "    schedule_event_now(action, params=None, module=':NONE', priority=0, maintenance=False, destination=None, details=None, output=True, precondition=None)\n",
      "    \n",
      "    schedule_event_relative(time_delay, action, params=None, module=':NONE', priority=0, maintenance=False, destination=None, details=None, output=True, time_in_ms=False, precondition=None)\n",
      "    \n",
      "    schedule_mod_buffer_chunk(buffer, mod_list_or_spec, time, module=':NONE', priority=0, output='low', time_in_ms=False)\n",
      "    \n",
      "    schedule_set_buffer_chunk(buffer, chunk, time, module=':NONE', priority=0, output='low', time_in_ms=False, requested=True)\n",
      "    \n",
      "    schedule_simple_mod_buffer_chunk(buffer, mod_list_or_spec, time, module='NONE', priority=0)\n",
      "    \n",
      "    schedule_simple_set_buffer_chunk(buffer, chunk, time, module='NONE', priority=0, requested=True)\n",
      "    \n",
      "    sdm(*params)\n",
      "    \n",
      "    sdp(*params)\n",
      "    \n",
      "    set_buffer_chunk(buffer_name, chunk_name, requested=True)\n",
      "    \n",
      "    set_chunk_slot_value(chunk_name, slot_name, new_value)\n",
      "    \n",
      "    set_current_model(name)\n",
      "    \n",
      "    set_parameter_value(param, value)\n",
      "    \n",
      "    set_system_parameter_value(param, value)\n",
      "    \n",
      "    simulate_retrieval_request(*spec)\n",
      "    \n",
      "    sorted_module_names()\n",
      "    \n",
      "    spp(*params)\n",
      "    \n",
      "    start(host=None, port=None)\n",
      "    \n",
      "    start_hand_at_mouse()\n",
      "    \n",
      "    stop()\n",
      "    \n",
      "    stop_output()\n",
      "    \n",
      "    stop_recording_history(*params)\n",
      "    \n",
      "    trigger_reward(reward, maintenance=False)\n",
      "    \n",
      "    undefine_module(name)\n",
      "    \n",
      "    unhide_output()\n",
      "    \n",
      "    used_production_buffers()\n",
      "    \n",
      "    whynot(*params)\n",
      "    \n",
      "    whynot_dm(*params)\n",
      "\n",
      "DATA\n",
      "    current_connection = <actr.actr object>\n",
      "    locals = <_thread._local object>\n",
      "\n",
      "FILE\n",
      "    c:\\users\\cleme\\documents\\education\\rug\\first-year_research\\my_project\\model\\actr.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(actr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Experiment part ###\n",
    "\n",
    "def __init__(iteration, rehearsal_time, list_length, list_amount=3, path=\".\"):\n",
    "    subject = ''\n",
    "\n",
    "    current_list = ''\n",
    "    \n",
    "    associated_list = ''\n",
    "\n",
    "    recalled_words = defaultdict(list)\n",
    "\n",
    "    rehearsed_words =  defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    #list_amount = 3   # No of lists (100, 200, 1000, 2000 AND 5000)\n",
    "\n",
    "    #Set below where function is actually called\n",
    "    list_length = list_length   # No of words in a list\n",
    "    rehearsal_time = rehearsal_time  # No of seconds for which rehearsal happens and each word is shown\n",
    "\n",
    "    delay = 1  #delay between rehearsal and recall\n",
    "\n",
    "    recall_time = 90\n",
    "    \n",
    "    #distractor_time = 30 #set further below\n",
    "    \n",
    "    word_lists_dict = defaultdict(list)\n",
    "    \n",
    "    # Ensure there are enough unique words to create the word lists\n",
    "    word_dict = {\"positive\": [\"positive\" + str(i) for i in range(999)],\n",
    "                 \"negative\": [\"negative\" + str(i) for i in range(999)],\n",
    "                 \"neutral\": [\"neutral\" + str(i) for i in range(999)]}\n",
    "\n",
    "    filename = f'{path}\\words_{list_length}_lists_{list_amount}_rh_time_{rehearsal_time}_rec_time_{recall_time}_delay_{delay}_{iteration}.txt'\n",
    "    \n",
    "    results = {}\n",
    "\n",
    "    results['x'] = {'data': [], # will be appended later in the analytics function\n",
    "                          'info': \"Storing range(len(word_lists_dict[0])) here\"}\n",
    "\n",
    "    results['rehearse_frequency'] = {'data': None,# will be appended later in the analytics function\n",
    "                                     'info': \"Storing list(rehearse_frequency.values()) here\"}\n",
    "\n",
    "    results['recall_probability'] = {'data': None, # will be appended later in the analytics function\n",
    "                                        'info': \"Storing list(recall_probability.values()) here\"}\n",
    "\n",
    "    results['first_recall'] = {'data': None, # will be appended later in the analytics function\n",
    "                               'info': \"Storing list(first_probability.values()) here\"}\n",
    "    \n",
    "    results['pli'] = {'data': None, # will be appended later in the analytics function\n",
    "                         'info': \"Storing avg PLIs per agent here\"}\n",
    "    \n",
    "    results['transitions'] = {'data': None, # will be appended later in the analytics function\n",
    "                         'info': \"Storing recall transitions here\"}\n",
    "    \n",
    "    results['neg_thought_train'] = {'data': None, # will be appended later in the analytics function\n",
    "                         'info': \"Storing negative thought train lengths here\"}\n",
    "\n",
    "    with open(filename, 'w') as outfile:\n",
    "        json.dump(results, outfile)\n",
    "\n",
    "    with open(filename) as json_file:\n",
    "        results = json.load(json_file)\n",
    "#         #print(results)\n",
    "    \n",
    "    globals().update(locals())  ## Making everything public, worst code you can ever write!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-3f307f7b3463>, line 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-4-3f307f7b3463>\"\u001b[1;36m, line \u001b[1;32m28\u001b[0m\n\u001b[1;33m    else:\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def add_words(i, list_length):\n",
    "    '''\n",
    "    Add the words to the word lists, ensures valence categories are balanced\n",
    "    '''\n",
    "    global word_lists_dict\n",
    "\n",
    "    amnt_wanted = (list_length)/3#-2)/3 #not needed here because Murdock experiment # Amount of each valence wanted, minus 2 neutrals controlling for primacy\n",
    "    amt_positive, amt_negative, amt_neutral, count = 0, 0, 0, 0\n",
    "    while len(word_lists_dict[i]) != list_length:\n",
    "        count += 1\n",
    "        #print(f\"...................{count,word_lists_dict[i]}\")\n",
    "        if count >= 9999: # IF it takes too long to create a unique list at random, start over\n",
    "            word_lists_dict[i] = []\n",
    "            add_words(i, list_length)\n",
    "        if len(word_lists_dict[i]) == 0: # Place two neutral words at the start to control for primacy effects\n",
    "            word_to_add1 = word_dict[\"neutral\"][random.randint(0, len(word_dict[\"neutral\"])-1)]\n",
    "            word_to_add2 = word_dict[\"neutral\"][random.randint(0, len(word_dict[\"neutral\"])-1)]\n",
    "            if word_to_add1 not in word_lists_dict[i] and word_to_add2 not in word_lists_dict[i] and word_to_add1 != word_to_add2:\n",
    "                word_lists_dict[i].append(word_to_add1)\n",
    "                word_lists_dict[i].append(word_to_add2)\n",
    "            else:\n",
    "                continue # skip this loop iteration                   \n",
    "        else: \n",
    "            random_valence = random.choice([\"positive\", \"negative\", \"neutral\"])\n",
    "            word_to_add = word_dict[random_valence][random.randint(0, len(word_dict[random_valence])-1)]\n",
    "            if word_to_add not in word_lists_dict[i] and word_lists_dict[i][-1] not in word_dict[random_valence] and \\\n",
    "               amt_positive <= amnt_wanted and amt_negative <= amnt_wanted and amt_neutral <= amnt_wanted:\n",
    "                if random_valence == \"positive\" and amt_positive < amnt_wanted:\n",
    "                    amt_positive += 1\n",
    "                elif random_valence == \"negative\" and amt_negative < amnt_wanted:\n",
    "                    amt_negative +=1\n",
    "                elif random_valence == \"neutral\" and amt_neutral < amnt_wanted:\n",
    "                    amt_neutral +=1\n",
    "                else:\n",
    "                    continue # skip this loop iteration\n",
    "                word_lists_dict[i].append(word_to_add)\n",
    "\n",
    "def create_lists(list_amount=3, list_length=2):\n",
    "    '''\n",
    "    Create the wordlists used during the free recall tasks \n",
    "    '''  \n",
    "    global word_lists_dict \n",
    "\n",
    "    for i in range(list_amount):\n",
    "        print(f'List {i+1}/{list_amount} created!', end=\"\\r\")\n",
    "        add_words(i, list_length)\n",
    "\n",
    "    # Save the dictionary to a .pickle file, so we do not have to create the word lists everytime we run the model                    \n",
    "    file = open(f\"word_lists/word_lists_dict_{list_length}_{list_amount}.pickle\",\"wb\")\n",
    "    pickle.dump(word_lists_dict, file)\n",
    "    file.close()\n",
    "    return word_lists_dict\n",
    "\n",
    "# Check if the word lists already exist, else create new word lists\n",
    "def check_and_create_lists():\n",
    "    global word_lists_dict\n",
    "    try:\n",
    "        file = open(f\"word_lists/word_lists_dict_{list_length}_{list_amount}.pickle\",\"rb\")\n",
    "        #file = open(f\"word_lists_dict_100_items_only.pickle\",\"rb\")\n",
    "        word_lists_dict = pickle.load(file)  \n",
    "        file.close()\n",
    "        print(\"\\nSuccesfully loaded the word lists!\\n\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"\\nCreating word lists!\\n\")\n",
    "        #amount_to_create = list_amount                              \n",
    "        word_lists_dict = create_lists(list_amount,list_length)\n",
    "\n",
    "def display_word_lists():\n",
    "    '''\n",
    "    Display the word lists loaded/created\n",
    "    '''\n",
    "    for key, value in word_lists_dict.items():\n",
    "        print(f'List {key}:\\n {value}\\n')\n",
    "\n",
    "def close_exp_window():\n",
    "    '''\n",
    "    Close opened ACT-R window\n",
    "    '''\n",
    "    return actr.current_connection.evaluate_single(\"close-exp-window\")\n",
    "\n",
    "\n",
    "def prepare_for_memorization():\n",
    "    '''\n",
    "    Enable rehearsing productions to start the memorization phase \n",
    "    '''    \n",
    "    \n",
    "    #actr.run(1, False)\n",
    "    \n",
    "    enable_list = [\"rehearse-first\", \"rehearse-second\", \"rehearse-third\", \"rehearse-fourth\", \n",
    "                    \"rehearse-first-default\", \"rehearse-second-default\", \"rehearse-third-default\",\n",
    "                    \"rehearse-fourth-default\", \"rehearse-it\", \"rehearse-it-wrong-word\", \"skip-rehearse-1\",\n",
    "                    \"skip-rehearse-2\", \"skip-rehearse-3\", \"skip-rehearse-4\", \"attend-new-word\",\n",
    "                    \"initiate-rumination\", \"continue-rumination-1\", \"continue-rumination-2\",\n",
    "                    \"wait-1\", \"wait-2\", \"wait-3\", \"wait-4\", \"ruminate\", \"finish-recall-1\",\n",
    "                   \"finish-recall-2\"]\n",
    "    \n",
    "    disable_list = [\"retrieve-a-word\", \"recall-a-word\", \"stop-recall\", \"ruminate\"]\n",
    "    \n",
    "    for prod in disable_list:\n",
    "        actr.pdisable(prod)\n",
    "        \n",
    "    for prod in enable_list:\n",
    "        actr.penable(prod)   \n",
    "    \n",
    "    actr.goal_focus(\"goal\") # set goal to start memorization\n",
    "    \n",
    "    for buff in [\"imaginal\", \"retrieval\", \"production\"]:\n",
    "        actr.clear_buffer(buff)  \n",
    "    \n",
    "    #actr.run(1, False)\n",
    "    \n",
    "    for buff in [\"imaginal\", \"retrieval\", \"production\"]:\n",
    "        actr.clear_buffer(buff)\n",
    "\n",
    "    \n",
    "def prepare_for_recall(distractor=0): \n",
    "    '''\n",
    "    Disable rehearsing productions, and clearing buffer contents to start the recalling phase \n",
    "    '''\n",
    "    if distractor: #disable distractor or memorization PRs\n",
    "        \n",
    "        disable_list = [\"crowd-out-wm\", \"continue-task\"]\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        disable_list = [\"rehearse-first\", \"rehearse-second\", \"rehearse-third\", \"rehearse-fourth\", \n",
    "                        \"rehearse-first-default\", \"rehearse-second-default\", \"rehearse-third-default\",\n",
    "                        \"rehearse-fourth-default\", \"rehearse-it\", \"rehearse-it-wrong-word\", \"skip-rehearse-1\",\n",
    "                        \"skip-rehearse-2\", \"skip-rehearse-3\", \"skip-rehearse-4\", \"attend-new-word\",\n",
    "                       \"initiate-rumination\", \"continue-rumination-1\", \"continue-rumination-2\",\n",
    "                        \"wait-1\", \"wait-2\", \"wait-3\", \"wait-4\", \"ruminate\", \"finish-recall-1\",\n",
    "                       \"finish-recall-2\"]\n",
    "    \n",
    "    #enable list is the same either way\n",
    "    enable_list = [\"retrieve-a-word\", \"recall-a-word\", \"stop-recall\", \"ruminate\"]\n",
    "    \n",
    "    for prod in disable_list:\n",
    "        actr.pdisable(prod)\n",
    "\n",
    "    for prod in enable_list:\n",
    "        actr.penable(prod)\n",
    "        \n",
    "    actr.run(delay, False) \n",
    "    \n",
    "    for buff in [\"imaginal\", \"retrieval\", \"production\"]:\n",
    "        actr.clear_buffer(buff) \n",
    "        \n",
    "def prepare_for_distractor(): \n",
    "    '''\n",
    "    Disable rehearsing productions, and clearing buffer contents to start the distractor task \n",
    "    '''\n",
    "    disable_list = [\"rehearse-first\", \"rehearse-second\", \"rehearse-third\", \"rehearse-fourth\", \n",
    "                    \"rehearse-first-default\", \"rehearse-second-default\", \"rehearse-third-default\",\n",
    "                    \"rehearse-fourth-default\", \"rehearse-it\", \"rehearse-it-wrong-word\", \"skip-rehearse-1\",\n",
    "                  \"skip-rehearse-2\", \"skip-rehearse-3\", \"skip-rehearse-4\", \"attend-new-word\",\n",
    "                   \"initiate-rumination\", \"continue-rumination-1\", \"continue-rumination-2\",\n",
    "                   \"wait-1\", \"wait-2\", \"wait-3\", \"wait-4\", \"ruminate\", \"finish-recall-1\",\n",
    "                   \"finish-recall-2\"]\n",
    "    \n",
    "    enable_list = [\"crowd-out-wm\", \"continue-task\"]\n",
    "    \n",
    "    for prod in disable_list:\n",
    "        actr.pdisable(prod)\n",
    "\n",
    "    for prod in enable_list:\n",
    "        actr.penable(prod)\n",
    "        \n",
    "    actr.run(delay, False) \n",
    "    \n",
    "    for buff in [\"imaginal\", \"retrieval\", \"production\"]:\n",
    "        actr.clear_buffer(buff) \n",
    "\n",
    "def setup_dm(word_lists_dict, rumination_chunks=0):\n",
    "    '''\n",
    "    Add words to declarative memory, since it can be assumed the test subjects know the English language already\n",
    "    '''\n",
    "    #print(\"\\n\\n############################################# Inside setup_dm i.e. Declarative Memory\")\n",
    "    \n",
    "    rumination_list = []\n",
    "    if rumination_chunks > 0:\n",
    "        for i in range(rumination_chunks):\n",
    "            actr.add_dm(('rumination'+str(i), 'isa', 'memory', 'word', 'rumination'+str(i),\n",
    "                         'valence', 'RED', 'context', 'rumination')) #, 'type', 'rumination'\n",
    "            rumination_list.append(('rumination'+str(i)).upper())\n",
    "    \n",
    "        #set creation times and times of prior reference for each chunk  \n",
    "    actr.sdp(':reference-list', list(np.linspace(0, -1000, 600)), ':creation-time', -1000)\n",
    "    \n",
    "    neg_word_list = []\n",
    "    colour_conversion = {'pos': 'GREEN', 'neg': 'RED', 'neu': 'BLACK'}\n",
    "    for list_idx, word_list in word_lists_dict.items():\n",
    "        i = 0\n",
    "        for idx, word in enumerate(word_list):\n",
    "            valence = ''.join([char for char in word if not char.isdigit()])[:3]\n",
    "            #we have to first add only the negative words s.t. we can set the similarities with the rumination chunks via sdp (sdp would otherwise set the similarities for all chunks)\n",
    "            if valence == 'neg':\n",
    "                actr.add_dm((valence+str(i)+\"-\"+str(list_idx), 'isa', 'memory', 'word', \"'\"+word+\"'\", 'valence', colour_conversion[valence],\n",
    "                            'context', 'list'+str(list_idx), 'type', 'on-task')) #, 'type', 'on-task'\n",
    "                neg_word_list.append((valence+str(i)+\"-\"+str(list_idx).upper()))\n",
    "                i += 1\n",
    "                \n",
    "#     for chunk in rumination_list:  \n",
    "#         actr.sdp(':sjis', [[chunk, 1]])\n",
    "    \n",
    "#     for word in neg_word_list:  \n",
    "#         actr.sdp(':sjis', [[word, 1]])   \n",
    "    \n",
    "    if rumination_chunks > 0:\n",
    "        #adding connection strength to negative valence for negative words and rumination chunks\n",
    "        actr.sdp(':sjis', [['RED', 2.5]])\n",
    "        \n",
    "        #adding chunks that relate to neutral and positive words, respectively. This is to ensure a balance in spreading activation\n",
    "        mindwandering_chunks = rumination_chunks//2\n",
    "        if mindwandering_chunks > 0:\n",
    "            for i in range(mindwandering_chunks):\n",
    "                actr.add_dm(('mindwandering'+str(i), 'isa', 'memory', 'word', 'mw'+str(i),\n",
    "                             'valence', 'BLACK', 'context', 'mindwandering')) #, 'type', 'mindwandering'\n",
    "\n",
    "        daydreaming_chunks = rumination_chunks//2\n",
    "        if daydreaming_chunks > 0:\n",
    "            for i in range(daydreaming_chunks):\n",
    "                actr.add_dm(('daydreaming'+str(i), 'isa', 'memory', 'word', 'dd'+str(i),\n",
    "                             'valence', 'GREEN', 'context', 'daydreaming')) #, 'type', 'daydreaming'\n",
    "    \n",
    "    #adding the remaining words (positive + neutral after setting connection strengths between rumination chunks and negative words)\n",
    "    for list_idx, word_list in word_lists_dict.items():\n",
    "        i, j = 0, 0\n",
    "        for idx, word in enumerate(word_list):\n",
    "            valence = ''.join([char for char in word if not char.isdigit()])[:3]\n",
    "            #we have to first add only the negative words s.t. we can set the similarities with the rumination chunks via sdp (sdp would otherwise set the similarities for all chunks)\n",
    "            if valence == 'pos':\n",
    "                actr.add_dm((valence+str(i)+\"-\"+str(list_idx), 'isa', 'memory', 'word', \"'\"+word+\"'\", 'valence', colour_conversion[valence],\n",
    "                            'context', 'list'+str(list_idx), 'type', 'on-task')) #, 'type', 'on-task'\n",
    "                i += 1\n",
    "            elif valence == 'neu':\n",
    "                actr.add_dm((valence+str(j)+\"-\"+str(list_idx), 'isa', 'memory', 'word', \"'\"+word+\"'\", 'valence', colour_conversion[valence],\n",
    "                            'context', 'list'+str(list_idx), 'type', 'on-task')) #, 'type', 'on-task'\n",
    "                j += 1\n",
    "                \n",
    "\n",
    "                \n",
    "    #         if idx == 0:\n",
    "    #             print(\"\\n Emaple of a chunk added in Declarative Memory is \\n\")\n",
    "    #             print('item'+str(idx), 'isa', 'memory', 'word', \"'\"+word+\"'\", 'valence', colour_conversion[valence],\"\\n\")\n",
    "\n",
    "    \n",
    "def setup_experiment(human=True):\n",
    "    '''\n",
    "    Load the correct ACT-R model, and create a window to display the words\n",
    "    '''\n",
    "#     print(\"\\n\\n############################################# Inside setup_experiment\")\n",
    "#     print(f'\\nSubject = {subject}\\n')  \n",
    "\n",
    "    loaded = None\n",
    "    if subject == \"controls\":\n",
    "        loaded = actr.load_act_r_model(r\"C:\\Users\\cleme\\Documents\\Education\\RUG\\First-Year_Research\\My_Project\\Model\\models\\general_free_recall_model_alt_v1_originalSolution.lisp\")\n",
    "        #loaded = actr.load_act_r_model(r\"C:\\Users\\cleme\\Documents\\Education\\RUG\\First-Year_Research\\My_Project\\Model\\models\\csm_free_recall_model.lisp\")\n",
    "    elif subject == \"depressed\":\n",
    "        loaded = actr.load_act_r_model(r\"C:\\Users\\cleme\\Documents\\Education\\RUG\\First-Year_Research\\My_Project\\Model\\models\\rumination_free_recall_model_alt_v1_originalSolution.lisp\")\n",
    "    \n",
    "    #print(\"\\n\\n############################################# Inside setup_experiment\")\n",
    "    #print(f'\\nLoaded Act-r model = {loaded}\\n')  \n",
    "\n",
    "    window = actr.open_exp_window(\"Free Recall Experiment\", width=1024, height=768, visible=human) # 15inch resolution window\n",
    "    actr.install_device(window) \n",
    "    return window    \n",
    "\n",
    "# def record_associated_list(item):\n",
    "#     '''\n",
    "#     Register which list the recalled words belong to (to identify prior-list intruisions)\n",
    "#     '''\n",
    "#     associated_list = item\n",
    "\n",
    "def record_words_recalled(item1, item2):\n",
    "    '''\n",
    "    Register which words were recalled during the experiment for a specific wordlist and strip the numbers\n",
    "    '''\n",
    "    valence = ''.join(char for char in item1 if not char.isdigit())\n",
    "    item_idx = ''.join(char for char in item1 if char.isdigit())\n",
    "    context = str(item2)\n",
    "    \n",
    "    if str(item2) != 'RUMINATION':\n",
    "        recalled_words[current_list].append((valence, item_idx, context))\n",
    "    \n",
    "    #print(valence, item_idx, context)\n",
    "\n",
    "def record_words_rehearsed(item):\n",
    "    '''\n",
    "    Register amount of rehearsals per word for each wordlist\n",
    "    '''\n",
    "    rehearsed_words[current_list][item] += 1\n",
    "\n",
    "def create_lplot(idx, xlabel, ylabel, x, y, xticks_len, filename, ytick_range=None, show=False):\n",
    "    '''\n",
    "    Create line plot using matplotlib\n",
    "    '''\n",
    "    plt.figure(idx)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.plot(x, y)\n",
    "    plt.xticks(np.arange(0, xticks_len, 1)) \n",
    "    plt.yticks(ytick_range)\n",
    "    #plt.savefig(\"images/\"+subject+\"_\"+filename, bbox_inches='tight')\n",
    "    if show:\n",
    "        plt.show()    \n",
    "\n",
    "        \n",
    "def create_result_dict():\n",
    "    '''\n",
    "    Use a module-level function, instead of lambda function, to enable pickling it\n",
    "    '''\n",
    "    return defaultdict(int)\n",
    "\n",
    "## Creating different pickle files to store results from multiple hyper-parameter values.\n",
    "\n",
    "\n",
    "def analysis(wlist_amount, show_plots=False):\n",
    "    '''\n",
    "    Review results of the recall experiment\n",
    "    '''\n",
    "    global results\n",
    "    result_dict = defaultdict(create_result_dict) # instead of defaultdict(lambda: defaultdict(int))\n",
    "    first_recall = defaultdict(int)\n",
    "    recall_probability = defaultdict(int)\n",
    "    rehearse_frequency = defaultdict(int)\n",
    "    pli_dict = defaultdict(int)\n",
    "    transitions_amnt = 0\n",
    "    thought_train_len = []\n",
    "    \n",
    "\n",
    "    for key, val in recalled_words.items():\n",
    "        thought_train_len.extend([(k, sum(1 for _ in count)) for k, count in groupby([val[0] for val in val[2:]])])\n",
    "        for idx, (retrieved_word, item_num, _) in enumerate(val[2:]):\n",
    "            if idx != 0:\n",
    "                if retrieved_word != val[2:][idx-1][0]:\n",
    "                    transitions_amnt += 1/wlist_amount # average over word lists\n",
    "    print(f'Avg. Amount of recall transitions = {int(transitions_amnt)}')\n",
    "    \n",
    "    neg_thought_train_len = 0\n",
    "    neg_divider = 0.0001\n",
    "    for x in thought_train_len:\n",
    "        if x[0] == 'negative':\n",
    "            neg_divider += 1\n",
    "            neg_thought_train_len += x[1]\n",
    "    avg_neg_thought_train_len = round(neg_thought_train_len/neg_divider, 3)\n",
    "    print(f'Avg. Negative Thought train length = {avg_neg_thought_train_len}')            \n",
    "    \n",
    "    for list_num, wlist in word_lists_dict.items():\n",
    "        if list_num < wlist_amount:\n",
    "            for key, val in recalled_words.items():\n",
    "                if key==list_num:\n",
    "                    first_recall[wlist.index(''.join(val[0][0:2]))] += 1\n",
    "                    for idx, word in enumerate(wlist):\n",
    "                        first_recall[idx] += 0\n",
    "                        if ((''.join(char for char in word if not char.isdigit()), \n",
    "                             ''.join(char for char in word if char.isdigit()), val[0][2])) in val:\n",
    "                            recall_probability[idx] += 1\n",
    "                        else:\n",
    "                            recall_probability[idx] += 0\n",
    "                for retrieved_word, item_num, list_idx in val[2:4]:\n",
    "                    result_dict[\"pstart\"][retrieved_word] += 1  \n",
    "                for retrieved_word, item_num, list_idx in val[4:-2]:\n",
    "                    result_dict[\"pstay\"][retrieved_word] += 1\n",
    "                for retrieved_word, item_num, list_idx in val[-2:]:\n",
    "                    result_dict[\"pstop\"][retrieved_word] += 1 \n",
    "            for key, val in rehearsed_words.items():\n",
    "                if key==list_num:\n",
    "                    for idx, word in enumerate(wlist):\n",
    "                        rehearse_frequency[idx] += rehearsed_words[key][word]\n",
    "    \n",
    "    \n",
    "    for key, val in first_recall.items():\n",
    "        first_recall[key] = val/wlist_amount\n",
    "\n",
    "    for key, val in recall_probability.items():\n",
    "        recall_probability[key] = val/wlist_amount\n",
    "\n",
    "    for key, val in rehearse_frequency.items():\n",
    "        rehearse_frequency[key] = val/wlist_amount      \n",
    "        \n",
    "    \n",
    "    #Calculate prior-list intrustions\n",
    "    #subjects committed an average of 0.61 PLIs per list (Zaromb et al., 2006)\n",
    "    \n",
    "    if len(recalled_words) > 1:\n",
    "        overall_pli = 0\n",
    "        for key, value in recalled_words.items():\n",
    "            if key > 0:\n",
    "                intruding_list = []\n",
    "                pli = 0\n",
    "                for word_info in value:\n",
    "                    associated_list = int(re.findall(r'\\d+', word_info[2])[0]) #extract just the number from the context and turn into int\n",
    "                    if associated_list != key:\n",
    "                        intruding_list.append(associated_list)\n",
    "                        pli += 1\n",
    "\n",
    "                print(f'PLIs on list {key}: {pli}')\n",
    "                if intruding_list:\n",
    "                    print(f'The PLIs came from {intruding_list}')\n",
    "                overall_pli += pli\n",
    "                \n",
    "        \n",
    "            pli_dict[key] = overall_pli\n",
    "            \n",
    "        avg_pli = overall_pli/(len(recalled_words)-1)\n",
    "        print(f'Average number of PLIs: {avg_pli}') #minus 1 because no PLI possible on LIST0\n",
    "       \n",
    "    xticks_len = len(word_lists_dict[0])\n",
    "    \n",
    "    #results['x']['data'].append(range(len(word_lists_dict[0])))\n",
    "    #results['xticks_len']['data'].append(len(word_lists_dict[0]) )\n",
    "    results['rehearse_frequency']['data'] = list(rehearse_frequency.values())\n",
    "    results['recall_probability']['data'] = list(recall_probability.values())\n",
    "    results['first_recall']['data'] = list(first_recall.values())\n",
    "    results['pli']['data'] = list(pli_dict.values())\n",
    "    \n",
    "    with open(filename, 'w') as outfile:\n",
    "        json.dump(results, outfile)\n",
    "        \n",
    "    create_lplot(0, 'Serial input position', 'Rehearse Frequency', range(len(word_lists_dict[0])), list(rehearse_frequency.values()), \n",
    "                xticks_len, f'rehearse_frequency_{list_length}_{list_amount}_{rehearsal_time}_{recall_time}_{delay}.png', None, show_plots)\n",
    "\n",
    "    create_lplot(1, 'Serial input position', 'Starting Recall', range(len(word_lists_dict[0])), list(first_recall.values()), \n",
    "                xticks_len, f'starting_recall_{list_length}_{list_amount}_{rehearsal_time}_{recall_time}_{delay}.png', np.arange(0, .5, .1), show_plots)                \n",
    "\n",
    "    create_lplot(2, 'Serial input position', 'Recall Probability', range(len(word_lists_dict[0])), list(recall_probability.values()), \n",
    "                xticks_len, f'recall_probability_{list_length}_{list_amount}_{rehearsal_time}_{recall_time}_{delay}.png', np.arange(0, 1, .1), show_plots)   \n",
    "    \n",
    "#     create_lplot(3, 'Serial input position', 'Accuracy', range(len(word_lists_dict[0])), list(recall_accuracy.values()), \n",
    "#                 xticks_len, 'recall_accuracy.png', np.arange(0, 1, .1), show_plots) \n",
    "\n",
    "    file = open(\"results_\"+subject+\".pickle\",\"wb\")\n",
    "    pickle.dump(result_dict, file)\n",
    "    file.close()\n",
    "\n",
    "    return result_dict, avg_neg_thought_train_len, transitions_amnt\n",
    "\n",
    "def do_experiment(subj=\"controls\", human=False, wlist_amount=2000, distractor_time=0, rumination_chunks=0):\n",
    "    '''\n",
    "    Run the experiment\n",
    "    '''\n",
    "    check_and_create_lists()\n",
    "    global word_lists_dict, subject\n",
    "    \n",
    "    subject = subj\n",
    "    \n",
    "    assert wlist_amount <= len(word_lists_dict), \"Chosen too many lists, choose less or create more word lists using function: create_lists()\"\n",
    "    \n",
    "#     print(\"###################################################\\n\")\n",
    "#     print(\"The original word list \\n\")\n",
    "#     print(display_word_lists())\n",
    "    \n",
    "#     print(\"\\n###################################################\\n\")\n",
    "#     print(\"Experiment started, Trying to understand the flow\\n\")\n",
    "    \n",
    "    #buffers_to_clear = ['goal', \"imaginal\", \"retrieval\", \"production\"]\n",
    "    \n",
    "    \n",
    "    actr.reset()\n",
    "    \n",
    "    window = setup_experiment(human)\n",
    "    \n",
    "    setup_dm(word_lists_dict, rumination_chunks=rumination_chunks)\n",
    "\n",
    "    for idx, (key, value) in enumerate(word_lists_dict.items()):\n",
    "        \n",
    "        #window = setup_experiment(human)\n",
    "\n",
    "        global current_list\n",
    "        current_list = idx # keep track for which list words are recalled\n",
    "\n",
    "        #setup_dm(key, value)\n",
    "                \n",
    "        prepare_for_memorization()\n",
    "        \n",
    "        actr.mod_focus('context', 'list'+str(current_list))\n",
    "        \n",
    "        #actr.run(2, human)\n",
    "        \n",
    "        #actr.load_act_r_code('~;Users;cleme;Documents;Education;RUG;First-Year_Research;My_Project;Model;modelsset_all_base_levels.lisp')\n",
    "    \n",
    "        actr.add_command(\"retrieved-word\", record_words_recalled,\"Retrieves recalled words.\")\n",
    "        actr.add_command(\"rehearsed-word\", record_words_rehearsed,\"Retrieves rehearsed words.\")\n",
    "        \n",
    "    \n",
    "#         print(\"\\n##################  Model started rehearsal \")\n",
    "        for idx, word in enumerate(value):\n",
    "            actr.mod_focus('context', 'list'+str(current_list))\n",
    "            if \"neutral\" in word:\n",
    "                color = \"black\"\n",
    "            elif \"positive\" in word:\n",
    "                color = \"green\"\n",
    "            else:\n",
    "                color = \"red\"\n",
    "            actr.add_text_to_exp_window(window, word, x=475-len(word) , y=374, color=color, font_size=20) # change later \n",
    "            print(idx, word, f'list{key}')\n",
    "            \n",
    "            actr.run(rehearsal_time, human) # True when choosing Human, False when choosing differently\n",
    "            \n",
    "            #actr.whynot_dm()\n",
    "            #actr.print_dm_finsts()\n",
    "            #print(actr.buffer_chunk('goal'))\n",
    "#             actr.buffer_status('retrieval')\n",
    "#             actr.buffer_status('imaginal')\n",
    "            \n",
    "            actr.clear_exp_window(window)\n",
    "            actr.run(0.5, human)  # 500-ms blank screen \n",
    "        \n",
    "        if distractor_time:\n",
    "            prepare_for_distractor()\n",
    "            actr.mod_focus('state', 'begin-task')\n",
    "            actr.run(distractor_time, human)\n",
    "            \n",
    "        \n",
    "        prepare_for_recall(distractor_time)\n",
    "        \n",
    "        actr.goal_focus('startrecall')\n",
    "        actr.mod_focus('context', 'list'+str(current_list))\n",
    "\n",
    "        #actr.goal_focus('startrecall')\n",
    "       \n",
    "        #for buff in [\"imaginal\", \"retrieval\", \"production\"]:\n",
    "        #    actr.clear_buffer(buff)\n",
    "        \n",
    "        \n",
    "        #actr.remove_command(\"rehearsed-word\")\n",
    "        \n",
    "#         print(\"\\n##################  Model finished rehearsal, list of rehearsed words is \")\n",
    "#         print(f'{rehearsed_words}\\n')\n",
    "#         print(\"\\n##################  Model started recall \")\n",
    "        #actr.goal_focus(\"startrecall\") # set goal to start recalling\n",
    "    \n",
    "        actr.run(recall_time, human)  \n",
    "        \n",
    "#         for buffer in buffers_to_clear:\n",
    "#             actr.clear_buffer(buffer)\n",
    "    \n",
    "        #actr.remove_command(\"retrieved-word\")\n",
    "        \n",
    "#         print(\"\\n##################  Model finished recall, list of recalled words is \")\n",
    "#         print(f'{recalled_words}\\n')\n",
    "        print(f'Experiment {idx+1}/{wlist_amount} completed!', end=\"\\r\")\n",
    "        if idx == wlist_amount-1: # run for a chosen amount of word lists\n",
    "            break\n",
    "    close_exp_window() # close window at end of experiment\n",
    "    \n",
    "    num_recalled, num_recalled_unique = 0, 0\n",
    "    for key, val in recalled_words.items():\n",
    "        correct_recalls = []\n",
    "        print(key, current_list)\n",
    "        print(val)\n",
    "        for word in val:\n",
    "            if word[2] == f'LIST{key}':\n",
    "                correct_recalls.append(word[0:2])\n",
    "                num_recalled += 1\n",
    "        num_recalled_unique += len(set(correct_recalls))\n",
    "        print(f'\\n\\nList {key} (length={len(correct_recalls)}, unique={len(set(correct_recalls))})\\n')\n",
    "        \n",
    "    avg_recalled = num_recalled//wlist_amount\n",
    "    avg_unique_recalled = num_recalled_unique//wlist_amount\n",
    "    \n",
    "    print(f'Avg. Number of words recalled = {avg_recalled}')\n",
    "    print(f'Avg. Number of unique words recalled = {avg_unique_recalled}')\n",
    "    \n",
    "    #analysis(list_amount, False)\n",
    "    results, avg_neg_train, num_transitions = analysis(list_amount, False)        \n",
    "\n",
    "    for key, val in results.items():\n",
    "        print(f'{key} = {dict(val)}')\n",
    "    print()\n",
    " \n",
    "\n",
    "    print(\"\\n\\n#############################################\")\n",
    "    print(f'\\n[{subject}] Results!\\n')\n",
    "    return avg_recalled, avg_unique_recalled, avg_neg_train, num_transitions, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_agents = 5 #set number of agents per condition\n",
    "num_lists = 3 #number of lists per agent\n",
    "distractor_time = 0\n",
    "rumination_chunks = 0\n",
    "#subject = 'controls' # 'controls', 'depressed'\n",
    "\n",
    "#experimental conditions [rehearsal time, list length] from Murdock 1962 (and van Vugt 2012 [6,20])\n",
    "experimental_setup = [[6,24]] #   [2,10],[1,20],[2,15],[1,30],[2,20],[1,40]\n",
    "\n",
    "#to save files to different directory for different numbers of agents\n",
    "output_path = f'./murdock/agents_{num_agents}/'\n",
    "if not os.path.isdir(output_path):\n",
    "    os.mkdir(f'murdock/agents_{num_agents}/')\n",
    "path = output_path\n",
    "\n",
    "pstats = {}\n",
    "results_dict = {}\n",
    "valences = ['neutral', 'positive', 'negative']\n",
    "for parameter in experimental_setup:\n",
    "    rh = parameter[0]\n",
    "    ll = parameter[1]\n",
    "    \n",
    "    total_recalled = 0\n",
    "    total_unique = 0\n",
    "    \n",
    "    neg_train_list = []\n",
    "    transitions_list = []\n",
    "    \n",
    "    pstats[f'{rh}-{ll}'] = {'pstart': {'neutral':0, 'positive':0, 'negative':0},\n",
    "                            'pstop': {'neutral':0, 'positive':0, 'negative':0},\n",
    "                            'pstay': {'neutral':0, 'positive':0, 'negative':0}}\n",
    "    \n",
    "    print(\"-------------------------------------------------------------------\")\n",
    "    print(\"Experimental condition:\")\n",
    "    print(f\"Number of lists: {num_lists}\")\n",
    "    print(f\"Words per list: {ll}\")\n",
    "    print(f\"Rehearsal time: {rh} seconds\")\n",
    "    \n",
    "    for agent in range(num_agents):\n",
    "        \n",
    "        print(\"-------------------------------------------------------------------\")\n",
    "        print(f\"Started for agent_{agent}\")\n",
    "        print(f\"Words per list: {ll}, rehearsal time: {rh} sec\")\n",
    "        __init__(agent, rehearsal_time=rh, list_length=ll, list_amount=num_lists, path=path)\n",
    "\n",
    "        try:\n",
    "            num_recalled, num_unique, avg_neg_train, num_transitions, results = do_experiment('depressed',False,\n",
    "                                                                                              list_amount,\n",
    "                                                                                            distractor_time=distractor_time,\n",
    "                                                                                            rumination_chunks=rumination_chunks)\n",
    "            total_recalled += num_recalled\n",
    "            total_unique += num_unique\n",
    "            \n",
    "            neg_train_list.append(avg_neg_train)\n",
    "            transitions_list.append(num_transitions)\n",
    "            \n",
    "            for valence in valences:\n",
    "                pstats[f'{rh}-{ll}']['pstart'][valence] += results['pstart'][valence]\n",
    "                pstats[f'{rh}-{ll}']['pstay'][valence] += results['pstay'][valence]\n",
    "                pstats[f'{rh}-{ll}']['pstop'][valence] += results['pstop'][valence]\n",
    "        \n",
    "        except ValueError:\n",
    "            print(\"\\nAgent recalled 0 items.\")\n",
    "\n",
    "    avg_recall = total_recalled / num_agents\n",
    "    avg_unique = total_unique / num_agents\n",
    "    \n",
    "    avg_neg_train_len = sum(neg_train_list) / num_agents\n",
    "    avg_transitions = sum(transitions_list) / num_agents\n",
    "    \n",
    "    results_dict[f'Rate: {rh}, Items: {ll}'] = [avg_recall, avg_unique, avg_neg_train_len, avg_transitions]\n",
    "    \n",
    "    print(f\"Experimental Condition\\nWords per list: {ll}, rehearsal time: {rh} sec\")\n",
    "    print(f\"\\nAverage number of recalled words ({num_agents} agents): {avg_recall}\")\n",
    "    print(f\"Unique: {avg_unique}\")\n",
    "\n",
    "for key, value in results_dict.items():\n",
    "    print(f'\\n{key}')\n",
    "    print(f'\\nAverage number of recalled words: {value[0]}')\n",
    "    print(f'\\nAverage number of unique words: {value[1]}')\n",
    "    print(f'\\nAverage length of negative thought trains: {value[2]}')\n",
    "    print(f'\\nAverage number of recall transitions: {value[3]}')\n",
    "    print('-------------------------------------------------------------\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "max_list_length = 40\n",
    "f, ax = plt.subplots(1) #set up plot\n",
    "\n",
    "#path = f'murdock/agents_{num_agents}_controls_vV/'\n",
    "#path = f'murdock/agents_{num_agents}/'\n",
    "\n",
    "f.set_size_inches(20, 10.5)\n",
    "\n",
    "for key, value in results_dict.items():\n",
    "    print(f'\\n{key}')\n",
    "    print(f'\\nAverage number of recalled words: {value[0]}')\n",
    "    print(f'\\nAverage number of unique words: {value[1]}')\n",
    "    print(f'\\nAverage length of negative thought trains: {round(value[2],2)}')\n",
    "    print(f'\\nAverage number of recall transitions: {round(value[3],2)}')\n",
    "    print('-------------------------------------------------------------\\n')\n",
    "    \n",
    "for parameter in experimental_setup:\n",
    "    rh = parameter[0] #rehearsal time\n",
    "    ll = parameter[1] #words per list\n",
    "\n",
    "    files = [] #Storing all the relevant files to work on them later\n",
    "    pattern = f\"words_{ll}_lists_{num_lists}_rh_time_{rh}*.txt\" # Pattern for matching the filename for data retrieval\n",
    "    for file in os.listdir(path): #Lists all the files and directories within the folder\n",
    "        if fnmatch.fnmatch(file, pattern): #matches the above declared patter with the filenames from listdir()\n",
    "            files.append(file) #Appends the file to make it available for later use.\n",
    "    \n",
    "    # Initializing all the parameters needed for the plots\n",
    "    idx = [0,1,2]\n",
    "    xlabel = 'Serial Input Position'\n",
    "    ylabel = ['Rehearse Frequency','Starting Probability','Recall Probability']\n",
    "    xticks_len = max_list_length+10\n",
    "    rehearse_frequency = []\n",
    "    recall_probability = []\n",
    "    first_recall = []\n",
    "    pli_list = []\n",
    "    neg_thought_train = []\n",
    "    transitions = []\n",
    "    \n",
    "    for file in files: #load the result files\n",
    "        with open(f\"{path}/{file}\") as f:\n",
    "            recall_stats = json.load(f)\n",
    "            if recall_stats['recall_probability']['data']:\n",
    "                recall_probability.append(recall_stats['recall_probability']['data'])\n",
    "            else: #if an agent failed to recall anything...\n",
    "                recall_probability.append([0]*ll)\n",
    "            if recall_stats['pli']['data']:\n",
    "                pli_list.append(recall_stats['pli']['data'])\n",
    "            else:\n",
    "                pli_list.append([0]*ll)\n",
    "#             if results['neg_thought_train']['data']:\n",
    "#                 neg_thought_train.append(results['neg_thought_train']['data'])\n",
    "#             else:\n",
    "#                 neg_thought_train.append([0]*ll)\n",
    "#             if results['transitions']['data']:\n",
    "#                 transitions.append(results['transitions']['data'])\n",
    "#             else:\n",
    "#                 transitions.append([0]*ll)\n",
    "                \n",
    "                \n",
    "                \n",
    "    #calculating avg stats per input position across agents            \n",
    "    avg_recall_probs = [sum(x)/num_agents for x in zip(*recall_probability)]\n",
    "    avg_pli = [sum(x)/num_agents for x in zip(*pli_list)]\n",
    "    \n",
    "    \n",
    "    \n",
    "#     avg_neg_train = [sum(x)/num_agents for x in zip(*neg_thought_train)]\n",
    "#     avg_transitions = [sum(x)/num_agents for x in zip(*transitions)]\n",
    "    \n",
    "    print(f'{ll}-{rh}\\nP(First_Item): {round(avg_recall_probs[0],2)}\\nP(Final_Item): {round(avg_recall_probs[-1],2)}\\nAvg PLI: {sum(avg_pli)/(num_lists-1)}')\n",
    "    #print(f'\\nAverage negative thought train length: {round(sum(avg_neg_train)/(num_lists),2)}\\nAvg num transitions: {round(sum(avg_transitions)/(num_lists),2)}')\n",
    "    \n",
    "    #plot results\n",
    "    x = range(ll)\n",
    "    ax.plot(x[0:20], avg_recall_probs[2:22], marker = \"o\", label = f\"{20} items, {rh} sec\") #, color = 'red' \n",
    "    #ax.set_xlim([0,ll])\n",
    "    plt.xticks(np.arange(0, 20, step=1), fontsize = 18)\n",
    "    plt.yticks(fontsize = 18)# Set label locations\n",
    "    ax.set_ylim([0,1])\n",
    "    ax.set_ylabel('Recall probability', fontsize = 20)\n",
    "    ax.set_xlabel('Serial input position', fontsize = 20)\n",
    "    \n",
    "ax.legend()\n",
    "ax.legend(title='Condition', bbox_to_anchor=(1.05, 1), loc='upper left') #fontsize='xx-small')\n",
    "\n",
    "#(\"murdock/images/\"+subject+\"_\"+filename, bbox_inches='tight')\n",
    "\n",
    "\n",
    "# for condition, stats in pstats.items():\n",
    "#     print(f'\\n{condition}')\n",
    "#     for stat, vals in stats.items():\n",
    "#         print(f'\\n{stat}')\n",
    "#         total = sum(vals.values())\n",
    "#         for val, res in vals.items():\n",
    "#             print(f'{val}: {round(res/total,2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### do_experiment flow:\n",
    "\n",
    "1. check_and_create_lists\n",
    "\ta. create_lists\n",
    "\t   return word_lists_dict\n",
    "\t\ti. add_words\n",
    "            adds to word_lists_dict\n",
    "\n",
    "2. setup_experiment\n",
    "    returns window\n",
    "      model is loaded\n",
    "\n",
    "\n",
    "3. setup_dm\n",
    "\n",
    "\n",
    "4. prepare_for_recall\n",
    "\n",
    "\n",
    "5. close_exp_window\n",
    "\n",
    "\n",
    "6. analysis\n",
    "    return result_dict\n",
    "        contains pstart, pstay, pstop\n",
    "    prints Avg recall transitions\n",
    "    \n",
    "    prints Avg negative thought train length\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = []\n",
    "with(open(r\"word_lists\\word_lists_dict_20_3.pickle\", \"rb\")) as openfile:\n",
    "    while True:\n",
    "        try:\n",
    "            objects.append(pickle.load(openfile))\n",
    "        except EOFError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for idx, (key, val) in enumerate(word_lists_dict.items()):\n",
    "#    print(idx, (key, val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(f\"word_lists/word_lists_dict_30_3.pickle\",\"rb\")\n",
    "#file = open(f\"word_lists_dict_100_items_only.pickle\",\"rb\")\n",
    "word_lists_dict = pickle.load(file)  \n",
    "file.close()\n",
    "\n",
    "word_lists_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#actr.reset()\n",
    "#setup_dm(word_lists_dict)\n",
    "#actr.sdp(':creation-time', -1000, ':reference-list', list(np.linspace(0, -1000, 50)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_lists_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recalled_words.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     for key, val in recalled_words.items():\n",
    "#         print(key, current_list)\n",
    "#         print(val)\n",
    "#         for word in val:\n",
    "#             print(word[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#actr.load_act_r_model(r\"C:\\Users\\cleme\\Documents\\Education\\RUG\\First-Year_Research\\My_Project\\Model\\models\\rumination_free_recall_model_v1.lisp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n",
      "#|Warning: Slot VALENCE invalid for type STUDY-WORDS but chunk-spec definition still created. |#\n"
     ]
    }
   ],
   "source": [
    "#setup_dm(word_lists_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
